{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from vocab_building.ipynb\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "import string\n",
    "import random\n",
    "import os\n",
    "import glob\n",
    "\n",
    "from vocab_building import load_tokenized_file, load_vocab, decode_vocab, nlp, get_vocab_indx_vector"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def find_files(path): return glob.glob(path)\\n\\nall_categories = []\\nfor filename in find_files('../data/languages/*.txt'):\\n    category = os.path.splitext(os.path.basename(filename))[0]\\n    all_categories.append(category)\\n    \\nn_categories_languages = len(all_categories)\\n\\nif n_categories_languages == 0:\\n    raise RuntimeError('Data not found.')\\n\\nprint('# categories:', n_categories_languages, all_categories)\\nall_categories.remove('combined')\\nall_categories.remove('hungarian')\\nprint('# categories:', n_categories_languages, all_categories)\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"def find_files(path): return glob.glob(path)\n",
    "\n",
    "all_categories = []\n",
    "for filename in find_files('../data/languages/*.txt'):\n",
    "    category = os.path.splitext(os.path.basename(filename))[0]\n",
    "    all_categories.append(category)\n",
    "    \n",
    "n_categories_languages = len(all_categories)\n",
    "\n",
    "if n_categories_languages == 0:\n",
    "    raise RuntimeError('Data not found.')\n",
    "\n",
    "print('# categories:', n_categories_languages, all_categories)\n",
    "all_categories.remove('combined')\n",
    "all_categories.remove('hungarian')\n",
    "print('# categories:', n_categories_languages, all_categories)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def find_files(path): return glob.glob(path)\\n\\nall_categories = []\\nfor filename in find_files('../data/scripts/*.txt'):\\n    category = os.path.splitext(os.path.basename(filename))[0]\\n    all_categories.append(category)\\n    \\nn_categories_languages = len(all_categories)\\n\\nif n_categories_languages == 0:\\n    raise RuntimeError('Data not found.')\\n\\nprint('# categories:', n_categories_languages, all_categories)\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"def find_files(path): return glob.glob(path)\n",
    "\n",
    "all_categories = []\n",
    "for filename in find_files('../data/scripts/*.txt'):\n",
    "    category = os.path.splitext(os.path.basename(filename))[0]\n",
    "    all_categories.append(category)\n",
    "    \n",
    "n_categories_languages = len(all_categories)\n",
    "\n",
    "if n_categories_languages == 0:\n",
    "    raise RuntimeError('Data not found.')\n",
    "\n",
    "print('# categories:', n_categories_languages, all_categories)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# categories: 5 ['garden', 'garden_small', 'music', 'music_small', 'small_combined']\n",
      "# categories: 2 ['garden_small', 'music_small']\n"
     ]
    }
   ],
   "source": [
    "def find_files(path): return glob.glob(path)\n",
    "\n",
    "all_categories = []\n",
    "for filename in find_files('../data/reviews/*.txt'):\n",
    "    category = os.path.splitext(os.path.basename(filename))[0]\n",
    "    all_categories.append(category)\n",
    "    \n",
    "n_categories_languages = len(all_categories)\n",
    "\n",
    "if n_categories_languages == 0:\n",
    "    raise RuntimeError('Data not found.')\n",
    "\n",
    "print('# categories:', n_categories_languages, all_categories)\n",
    "all_categories.remove('garden')\n",
    "all_categories.remove('music')\n",
    "all_categories.remove('small_combined')\n",
    "n_categories_languages = len(all_categories)\n",
    "print('# categories:', n_categories_languages, all_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # 'cuda' if torch.cuda.is_available() else "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=16\n",
    "TRAIN_TOKEN_LEN=256\n",
    "#VOCAB_SIZE = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        sequence_length,\n",
    "        vocab_file,\n",
    "        token_file\n",
    "    ):\n",
    "        self.sequence_length = sequence_length\n",
    "        self.load_words(vocab_file, token_file)\n",
    "    \n",
    "        self.uniq_words = len(self.vocab)\n",
    "\n",
    "    def load_words(self, vocab_file, token_file):\n",
    "        self.vocab = load_vocab(vocab_file) # mar_2023_lowercase_peter_pan_vocab.pt\n",
    "        self.raw_tokens = load_tokenized_file(token_file) # lowercase_peter_pan_Transformer_tok.pkl\n",
    "\n",
    "        self.num_samples = max(1, (len(self.raw_tokens) // TRAIN_TOKEN_LEN)) # Split raw tokens into groups of TRAIN_TOKEN_LEN\n",
    "        self.num_batches = max(1, self.num_samples // BATCH_SIZE)\n",
    "\n",
    "        print('Number of raw_tokens: ', len(self.raw_tokens))\n",
    "        print('Number of samples in a batch: ', self.num_samples)\n",
    "        print('Number of batches: ', self.num_batches)\n",
    "\n",
    "        return 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        #print('INDEX: ', index)\n",
    "        index = index * TRAIN_TOKEN_LEN\n",
    "        return (\n",
    "            torch.tensor(self.raw_tokens[index:index+self.sequence_length]).to(device), # x\n",
    "            torch.tensor(self.raw_tokens[index+1:index+self.sequence_length+1]).to(device), # y\n",
    "            0 # no cat\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_Dataset_multiple_sources(torch.utils.data.Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        sequence_length,\n",
    "        vocab_file,\n",
    "        token_file_1,\n",
    "        token_file_2\n",
    "    ):\n",
    "        self.sequence_length = sequence_length\n",
    "        self.load_words(vocab_file, token_file_1, token_file_2)\n",
    "    \n",
    "        self.uniq_words = len(self.vocab)\n",
    "\n",
    "    def load_words(self, vocab_file, token_file_1, token_file_2):\n",
    "        # We want the vocab to be constructed from all sources, but we need the raw token sets for each seperately.\n",
    "        # The category vector can just be a simple index vector.\n",
    "        self.vocab = load_vocab(vocab_file)\n",
    "        self.raw_tokens_1 = load_tokenized_file(token_file_1)\n",
    "        self.raw_tokens_2 = load_tokenized_file(token_file_2)\n",
    "\n",
    "        self.num_samples_1 = len(self.raw_tokens_1)\n",
    "        self.num_samples_2 = len(self.raw_tokens_2)\n",
    "\n",
    "        # This is iffy, because we aren't actually going through all of the \"samples\"\n",
    "        self.num_samples = max(1, ((self.num_samples_1 + self.num_samples_2) // TRAIN_TOKEN_LEN)) # Split raw tokens into groups of TRAIN_TOKEN_LEN\n",
    "        self.num_batches = max(1, self.num_samples // BATCH_SIZE)\n",
    "\n",
    "        print('Number of raw_tokens: ', len(self.raw_tokens_1 + self.raw_tokens_2))\n",
    "        print('Number of samples in a batch: ', self.num_samples)\n",
    "        print('Number of batches: ', self.num_batches)\n",
    "\n",
    "        return 1\n",
    "    \n",
    "    def random_choice(self, l):\n",
    "        return l[random.randint(0, len(l)-1)]\n",
    "    \n",
    "    def category_tensor(self, category):\n",
    "        li = all_categories.index(category)\n",
    "        if li == 0:\n",
    "            tensor = torch.zeros(self.sequence_length).to(device).long()\n",
    "        else:\n",
    "            tensor = torch.ones(self.sequence_length).to(device).long()\n",
    "        return tensor, li\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # This should pick a random source, grab it's category, and then grab a sequence associated with it.\n",
    "        # Pick random category\n",
    "        string_category= self.random_choice(all_categories)\n",
    "        category, category_index = self.category_tensor(string_category)\n",
    "\n",
    "        # Pick the right token samples based on the category\n",
    "        if category_index == 0:\n",
    "            current_sample = self.raw_tokens_1\n",
    "        else:\n",
    "            current_sample = self.raw_tokens_2\n",
    "            \n",
    "        # We cut off the potential of it being too long\n",
    "        random_index = random.randint(0, len(current_sample) - (self.sequence_length + 1)) \n",
    "        end_index = random_index + self.sequence_length\n",
    "        return ( # might break if it gets the very end?\n",
    "            torch.tensor(current_sample[random_index:end_index]).to(device), # x\n",
    "            torch.tensor(current_sample[random_index+1:end_index+1]).to(device), # y\n",
    "            category\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers):\n",
    "        super(GRU, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        # EMBEDDING\n",
    "        self.embedding = nn.Embedding(num_embeddings=input_size, embedding_dim=hidden_size)\n",
    "\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=0.2, batch_first=True)\n",
    "\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, input_token, hidden, batch_size):\n",
    "        #print('input_token shape: ', input_token.size()) # 16, 256 -- batch_size, sequence_len\n",
    "\n",
    "        embedded = self.embedding(input_token)\n",
    "        #print('embedded size: ', embedded.size()) # 16, 256, 1400 -- batch, sequence_length, input_size\n",
    "\n",
    "        out, hidden = self.gru(embedded, hidden)\n",
    "        \n",
    "        out = self.fc(out)\n",
    "\n",
    "        #print('out shape: ', out.size()) # 16, 256, 4822\n",
    "        #print('hidden shape: ', hidden.size()) # 3, 16, 1400\n",
    "\n",
    "        return out, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(self.n_layers, batch_size, self.hidden_size).to(device) # num_layers, batch_size, hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU_category(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers):\n",
    "        super(GRU_category, self).__init__()\n",
    "        self.input_size = input_size # 4822\n",
    "        self.hidden_size = hidden_size # 1400\n",
    "        self.output_size = output_size # 4822\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        # EMBEDDING\n",
    "        self.word_embedding = nn.Embedding(num_embeddings=output_size, embedding_dim=hidden_size)\n",
    "        self.cat_embedding = nn.Embedding(num_embeddings=2, embedding_dim=hidden_size)\n",
    "\n",
    "        self.gru = nn.GRU(hidden_size*2, hidden_size, n_layers, batch_first=True)\n",
    "\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, input_token, hidden, batch_size, category):\n",
    "        #print('input_token shape: ', input_token.size()) # 16, 256 -- batch_size, sequence_len\n",
    "        #print('cat size: ', category.size()) # [16, 1]\n",
    "        #print('cat: ', category)\n",
    "\n",
    "        # To determine:\n",
    "        # Do we concatenate the category and input token together, before embedding?\n",
    "        # Do we embed them seperately in different spaces, and then concatenate?\n",
    "        # Do we only embed the input, and then just concatenate the category?\n",
    "        # Do we do addition, or concatenation?\n",
    "        # Try embed both and then concatenate, but use the same embedding module.\n",
    "\n",
    "        embedded_word = self.word_embedding(input_token)\n",
    "        #print('embedded size: ', embedded_word.size()) # 16, 256, 1400 -- batch, sequence_length, input_size\n",
    "        \n",
    "        embedded_cat = self.cat_embedding(category)\n",
    "        #print('embedded cat size: ', embedded_cat.size()) # [16, 1, 64]\n",
    "\n",
    "        combined = torch.cat((embedded_word, embedded_cat), 2)\n",
    "\n",
    "        #print('combined size: ', combined.size())\n",
    "\n",
    "        out, hidden = self.gru(combined, hidden)\n",
    "        \n",
    "        out = self.fc(out)\n",
    "\n",
    "        #print('out shape: ', out.size()) # 16, 256, 4822\n",
    "        #print('hidden shape: ', hidden.size()) # 3, 16, 1400\n",
    "\n",
    "        return out, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(self.n_layers, batch_size, self.hidden_size).to(device) # num_layers, batch_size, hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU_with_cells(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers):\n",
    "        super(GRU_with_cells, self).__init__()\n",
    "        self.input_size = input_size \n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        # EMBEDDING\n",
    "        self.embedding = nn.Embedding(num_embeddings=input_size, embedding_dim=hidden_size)\n",
    "\n",
    "        #self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=0.2, batch_first=True)\n",
    "        # batch_size, input_size\n",
    "        self.gru_cell_1 = nn.GRUCell(hidden_size, hidden_size)\n",
    "\n",
    "        self.gru_cell_2 = nn.GRUCell(hidden_size, hidden_size)\n",
    "\n",
    "        self.gru_cell_3 = nn.GRUCell(hidden_size, hidden_size)\n",
    "\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, input_token, hidden_state, batch_size):\n",
    "        hidden_1, hidden_2, hidden_3 = hidden_state\n",
    "\n",
    "        # input_token size: 16, 256\n",
    "\n",
    "        embedded = self.embedding(input_token)\n",
    "\n",
    "        final_output_tensor = torch.empty((batch_size, 256, self.output_size)).to(device) # Final output needs to be 16, 256, 4822, or batch_size, sequence_length, output_size\n",
    "        # Embedded size: 16, 256, 1400 -- batch, sequence_length, input_size\n",
    "        for index in range(256):\n",
    "            initial = embedded[:,index,:]\n",
    "            #print('initial size: ', initial.size()) # 16, 1400\n",
    "            #print('hidden_size: ', hidden_1.size()) # 16, 1400\n",
    "            hidden_1 = self.gru_cell_1(initial, hidden_1)\n",
    "            hidden_2 = self.gru_cell_2(hidden_1, hidden_2)\n",
    "            hidden_3 = self.gru_cell_3(hidden_2, hidden_3)\n",
    "\n",
    "            out = self.fc(hidden_3)\n",
    "\n",
    "            #print('out size: ', torch.unsqueeze(out, 1).size()) # [16, 1, 4822]\n",
    "            # append to output tensor?\n",
    "            final_output_tensor[:, index, :] = torch.unsqueeze(out, 1)[:, 0, :]\n",
    "\n",
    "        #print(\"final_output_tensor size: \", final_output_tensor.size()) # 16, 256, 4822\n",
    "        # Ultimately, we want to return the final out vector of all predictions\n",
    "        return final_output_tensor, (hidden_1, hidden_2, hidden_3)\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden_1 = torch.zeros(batch_size, self.hidden_size).to(device) # num_layers, batch_size, hidden_size\n",
    "        hidden_2 = torch.zeros(batch_size, self.hidden_size).to(device)\n",
    "        hidden_3 = torch.zeros(batch_size, self.hidden_size).to(device)\n",
    "        return (hidden_1, hidden_2, hidden_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU_with_cells_category(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers):\n",
    "        super(GRU_with_cells_category, self).__init__()\n",
    "        self.input_size = input_size \n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        # EMBEDDING\n",
    "        self.word_embedding = nn.Embedding(num_embeddings=output_size, embedding_dim=hidden_size)\n",
    "        self.cat_embedding = nn.Embedding(num_embeddings=2, embedding_dim=hidden_size)\n",
    "\n",
    "        #self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=0.2, batch_first=True)\n",
    "        # batch_size, input_size\n",
    "        self.gru_cell_1 = nn.GRUCell(hidden_size*2, hidden_size) # dropout?\n",
    "\n",
    "        self.gru_cell_2 = nn.GRUCell(hidden_size, hidden_size)\n",
    "\n",
    "        self.gru_cell_3 = nn.GRUCell(hidden_size, hidden_size)\n",
    "\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, input_token, hidden_state, batch_size, category):\n",
    "        hidden_1, hidden_2, hidden_3 = hidden_state # should unpack\n",
    "\n",
    "        # input_token size: 16, 256\n",
    "\n",
    "        embedded_word = self.word_embedding(input_token) # You'll have to check size on this\n",
    "        #print('embedded size: ', embedded_word.size()) # 16, 256, 1400 -- batch, sequence_length, input_size\n",
    "        \n",
    "        embedded_cat = self.cat_embedding(category)\n",
    "        #print('embedded cat size: ', embedded_cat.size()) # [16, 1, 64]\n",
    "\n",
    "        combined = torch.cat((embedded_word, embedded_cat), 2)\n",
    "\n",
    "        final_output_tensor = torch.empty((batch_size, input_token.size()[1], self.output_size)).to(device) # Final output needs to be 16, 256, 4822, or batch_size, sequence_length, output_size\n",
    "        # Embedded size: 16, 256, 1400 -- batch, sequence_length, input_size\n",
    "        for index in range(input_token.size()[1]):\n",
    "            initial = combined[:,index,:]\n",
    "            #print('initial size: ', initial.size()) # 16, 1400 prediction: 1, 256\n",
    "            #print('hidden_size: ', hidden_1.size()) # 16, 1400 - 1, 256\n",
    "            hidden_1 = self.gru_cell_1(initial, hidden_1)\n",
    "            hidden_2 = self.gru_cell_2(hidden_1, hidden_2)\n",
    "            hidden_3 = self.gru_cell_3(hidden_2, hidden_3)\n",
    "\n",
    "            out = self.fc(hidden_3)\n",
    "\n",
    "            #print('out size: ', torch.unsqueeze(out, 1).size()) # [16, 1, 4822] 1, 1, 12923\n",
    "            # append to output tensor?\n",
    "            final_output_tensor[:, index, :] = torch.unsqueeze(out, 1)[:, 0, :]\n",
    "\n",
    "        #print(\"final_output_tensor size: \", final_output_tensor.size()) # 16, 256, 4822\n",
    "        # Ultimately, we want to return the final out vector of all predictions\n",
    "        return final_output_tensor, (hidden_1, hidden_2, hidden_3)\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden_1 = torch.zeros(batch_size, self.hidden_size).to(device) # num_layers, batch_size, hidden_size\n",
    "        hidden_2 = torch.zeros(batch_size, self.hidden_size).to(device)\n",
    "        hidden_3 = torch.zeros(batch_size, self.hidden_size).to(device)\n",
    "        return (hidden_1, hidden_2, hidden_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU_with_cells_category_edited(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers):\n",
    "        super(GRU_with_cells_category_edited, self).__init__()\n",
    "        self.input_size = input_size \n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        # EMBEDDING\n",
    "        self.word_embedding = nn.Embedding(num_embeddings=output_size, embedding_dim=hidden_size)\n",
    "        self.cat_embedding = nn.Embedding(num_embeddings=2, embedding_dim=hidden_size)\n",
    "\n",
    "        #self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=0.2, batch_first=True)\n",
    "        # batch_size, input_size\n",
    "        self.gru_cell_1 = nn.GRUCell(hidden_size*2, hidden_size)\n",
    "\n",
    "        self.gru_cell_2 = nn.GRUCell(hidden_size*2, hidden_size)\n",
    "\n",
    "        self.gru_cell_3 = nn.GRUCell(hidden_size*2, hidden_size)\n",
    "\n",
    "        self.fc = nn.Linear(hidden_size*2, output_size)\n",
    "        \n",
    "    def forward(self, input_token, hidden_state, batch_size, category):\n",
    "        hidden_1, hidden_2, hidden_3 = hidden_state # should unpack\n",
    "\n",
    "        # input_token size: 16, 256\n",
    "\n",
    "        embedded_word = self.word_embedding(input_token) # You'll have to check size on this\n",
    "        #print('embedded size: ', embedded_word.size()) # 16, 256, 1400 -- batch, sequence_length, input_size\n",
    "        #print('category size: ', category.size())\n",
    "        embedded_cat = self.cat_embedding(category)\n",
    "        #print('embedded cat size: ', embedded_cat.size()) # [16, 1, 64]\n",
    "\n",
    "        combined = torch.cat((embedded_word, embedded_cat), 2)\n",
    "\n",
    "        final_output_tensor = torch.empty((batch_size, input_token.size()[1], self.output_size)).to(device) # Final output needs to be 16, 256, 4822, or batch_size, sequence_length, output_size\n",
    "        # Embedded size: 16, 256, 1400 -- batch, sequence_length, input_size\n",
    "        # input_token.size()[1] is the sequence length\n",
    "        for index in range(input_token.size()[1]):\n",
    "            initial = combined[:,index,:]\n",
    "            cat = embedded_cat[:, index, :]\n",
    "            #print('initial size: ', initial.size()) # 16, 1400\n",
    "            #print('hidden_size: ', hidden_1.size()) # 16, 1400\n",
    "            hidden_1 = self.gru_cell_1(initial, hidden_1)\n",
    "            #print('hidden_1 size: ', hidden_1.size()) # 16, 256\n",
    "            hidden_2 = self.gru_cell_2(torch.cat((cat,hidden_1), 1), hidden_2)\n",
    "            hidden_3 = self.gru_cell_3(torch.cat((cat,hidden_2), 1), hidden_3)\n",
    "\n",
    "            out = self.fc(torch.cat((cat,hidden_3),1))\n",
    "\n",
    "            #print('out size: ', torch.unsqueeze(out, 1).size()) # [16, 1, 4822]\n",
    "            # append to output tensor?\n",
    "            final_output_tensor[:, index, :] = torch.unsqueeze(out, 1)[:, 0, :]\n",
    "\n",
    "        #print(\"final_output_tensor size: \", final_output_tensor.size()) # 16, 256, 4822\n",
    "        # Ultimately, we want to return the final out vector of all predictions\n",
    "        return final_output_tensor, (hidden_1, hidden_2, hidden_3)\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden_1 = torch.zeros(batch_size, self.hidden_size).to(device) # num_layers, batch_size, hidden_size\n",
    "        hidden_2 = torch.zeros(batch_size, self.hidden_size).to(device)\n",
    "        hidden_3 = torch.zeros(batch_size, self.hidden_size).to(device)\n",
    "        return (hidden_1, hidden_2, hidden_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, model, max_epochs, batch_size, cat = False):\n",
    "    train_losses = []\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, drop_last=True)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "\n",
    "        total_loss = 0\n",
    "        \n",
    "        for batch, (x, y, category) in enumerate(dataloader):\n",
    "            hidden_states = model.init_hidden(batch_size)\n",
    "\n",
    "            #print('x size: ', x.size()) # 16, 256\n",
    "            #print('category size: ', category.size()) # 16, 256\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if cat:\n",
    "                y_pred, hidden_states = model(x, hidden_states, batch_size, category)\n",
    "            else:\n",
    "                y_pred, hidden_states = model(x, hidden_states, batch_size)\n",
    "\n",
    "            #print('y_pred size: ', y_pred.size()) # [16, 4822] for cells, [16, 256, 4822] normal\n",
    "            #print('y_pred transposed size: ', y_pred.transpose(1, 2).size()) # [16, 4822, 256]\n",
    "\n",
    "            loss = criterion(y_pred.transpose(1, 2), y)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            print({ 'epoch': epoch, 'batch': batch, 'loss': loss.item() })\n",
    "\n",
    "        train_losses.append(total_loss/batch_size)\n",
    "\n",
    "    return train_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(dataset, model, text, next_words=100):\n",
    "    model.eval()\n",
    "\n",
    "    prediction = get_vocab_indx_vector(dataset.vocab, nlp, text)\n",
    "    tokens = torch.tensor(prediction).to(device)\n",
    "\n",
    "    state_h = model.init_hidden(1) # num_layers, batch_size, lstm_size\n",
    "\n",
    "    # Prime generation by feeding in initial input:\n",
    "    for p in range(len(tokens)-1):\n",
    "        _, state_h = model(tokens[p].view(1,-1), state_h)\n",
    "\n",
    "    last_token = tokens[-1]\n",
    "    for i in range(0, next_words):\n",
    "        y_pred, state_h = model(last_token.view(1,-1), state_h)\n",
    "        print('y_pred size: ', y_pred.size())\n",
    "        print('y_pred[0][-1] size: ', y_pred[0][-1].size())\n",
    "\n",
    "        last_word_logits = y_pred[0][-1]\n",
    "\n",
    "        # These are the probabilities\n",
    "        p = torch.nn.functional.softmax(last_word_logits, dim=0)\n",
    "        word_index = torch.multinomial(p, 1)[0]\n",
    "        top_values = torch.topk(p, 5)\n",
    "        top_words = top_values.indices\n",
    "        top_probs = top_values.values\n",
    "\n",
    "        #print('word index: ', word_index)\n",
    "        #print('top_words: ', top_words.tolist())\n",
    "        top_word_pred = decode_vocab(dataset.vocab, [word_index])\n",
    "        top_words_pred = decode_vocab(dataset.vocab, top_words.tolist())\n",
    "\n",
    "        #print('The top word predicted was: ', top_word_pred)\n",
    "        #print('The top five predictions were: ', top_words_pred)\n",
    "        #print('Their probabilites are: ', top_probs)\n",
    "\n",
    "        prediction.append(word_index)\n",
    "\n",
    "        last_token = torch.tensor([word_index]).to(device)\n",
    "\n",
    "    final_prediction = decode_vocab(dataset.vocab, prediction)\n",
    "    return final_prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_category(dataset, model, text, category, next_words=100):\n",
    "    model.eval()\n",
    "\n",
    "    prediction = get_vocab_indx_vector(dataset.vocab, nlp, text)\n",
    "    tokens = torch.tensor(prediction).to(device)\n",
    "\n",
    "    # Get category tensor\n",
    "    li = all_categories.index(category)\n",
    "    if li == 0:\n",
    "        category = torch.zeros(len(prediction)).to(device).long()\n",
    "    else:\n",
    "        category = torch.ones(len(prediction)).to(device).long()\n",
    "\n",
    "    print('cat size: ', category.size())\n",
    "    print('prediction size: ', tokens.size())\n",
    "\n",
    "    state_h = model.init_hidden(1) # num_layers, batch_size, lstm_size\n",
    "\n",
    "    # Prime generation by feeding in initial input:\n",
    "    for p in range(len(tokens)-1):\n",
    "        _, state_h = model(tokens[p].view(1,-1), state_h, 1, category[p].view(1,-1))\n",
    "        #print('state_h size: ', state_h.size())\n",
    "\n",
    "    last_token = tokens[-1]\n",
    "    for i in range(0, next_words):\n",
    "        y_pred, state_h = model(last_token.view(1,-1), state_h, 1, category[0].view(1,-1))\n",
    "        #print('y_pred size: ', y_pred.size()) # [16, 256, 12923], should be [1, 1, 12923]\n",
    "        #print('y_pred[0][-1] size: ', y_pred[0][-1].size())\n",
    "\n",
    "        last_word_logits = y_pred[0][-1]\n",
    "\n",
    "        # These are the probabilities\n",
    "        p = torch.nn.functional.softmax(last_word_logits, dim=0)\n",
    "        word_index = torch.multinomial(p, 1)[0]\n",
    "        top_values = torch.topk(p, 5)\n",
    "        #top_words = top_values.indices\n",
    "        #top_probs = top_values.values\n",
    "\n",
    "        #print('word index: ', word_index)\n",
    "        #print('top_words: ', top_words.tolist())\n",
    "        #top_word_pred = decode_vocab(dataset.vocab, [word_index])\n",
    "        #top_words_pred = decode_vocab(dataset.vocab, top_words.tolist())\n",
    "\n",
    "        #print('The top word predicted was: ', top_word_pred)\n",
    "        #print('The top five predictions were: ', top_words_pred)\n",
    "        #print('Their probabilites are: ', top_probs)\n",
    "\n",
    "        prediction.append(word_index)\n",
    "\n",
    "        last_token = torch.tensor([word_index]).to(device)\n",
    "\n",
    "    final_prediction = decode_vocab(dataset.vocab, prediction)\n",
    "    return final_prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = RNN_Dataset(TRAIN_TOKEN_LEN, \"mar_2023_lowercase_peter_pan_vocab.pt\", \"lowercase_peter_pan_Transformer_tok.pkl\")\n",
    "input_size = dataset.uniq_words # Should be size of vocab?\n",
    "hidden_size = 64\n",
    "n_layers = 3\n",
    "num_epochs = 50\n",
    "\n",
    "model = GRU(input_size, hidden_size, input_size, n_layers).to(device)\n",
    "\n",
    "file_path = f\"gru_trained.pt\"\n",
    "\n",
    "losses = train(dataset, model, num_epochs, BATCH_SIZE)\n",
    "\n",
    "torch.save(model.state_dict(), file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = RNN_Dataset(TRAIN_TOKEN_LEN, \"mar_2023_lowercase_peter_pan_vocab.pt\", \"lowercase_peter_pan_Transformer_tok.pkl\")\n",
    "input_size = dataset.uniq_words # Should be size of vocab?\n",
    "hidden_size = 512\n",
    "n_layers = 3\n",
    "num_epochs = 50\n",
    "\n",
    "model_with_cells = GRU_with_cells(input_size, hidden_size, input_size, n_layers).to(device)\n",
    "\n",
    "file_path_cells = f\"gru_trained_cells.pt\"\n",
    "\n",
    "losses_with_cells = train(dataset, model_with_cells, num_epochs, BATCH_SIZE)\n",
    "\n",
    "torch.save(model_with_cells.state_dict(), file_path_cells)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CATEGORY MODELS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n",
      "Vocabulary sizes:\n",
      "33806\n",
      "Number of raw_tokens:  1245513\n",
      "Number of samples in a batch:  4865\n",
      "Number of batches:  304\n",
      "{'epoch': 0, 'batch': 0, 'loss': 10.426780700683594}\n",
      "{'epoch': 0, 'batch': 1, 'loss': 10.294330596923828}\n",
      "{'epoch': 0, 'batch': 2, 'loss': 10.063139915466309}\n",
      "{'epoch': 0, 'batch': 3, 'loss': 9.715354919433594}\n",
      "{'epoch': 0, 'batch': 4, 'loss': 9.317502975463867}\n",
      "{'epoch': 0, 'batch': 5, 'loss': 8.895532608032227}\n",
      "{'epoch': 0, 'batch': 6, 'loss': 8.585273742675781}\n",
      "{'epoch': 0, 'batch': 7, 'loss': 8.206415176391602}\n",
      "{'epoch': 0, 'batch': 8, 'loss': 7.929788589477539}\n",
      "{'epoch': 0, 'batch': 9, 'loss': 7.640334129333496}\n",
      "{'epoch': 0, 'batch': 10, 'loss': 7.458206653594971}\n",
      "{'epoch': 0, 'batch': 11, 'loss': 7.248251914978027}\n",
      "{'epoch': 0, 'batch': 12, 'loss': 7.090412616729736}\n",
      "{'epoch': 0, 'batch': 13, 'loss': 6.993451118469238}\n",
      "{'epoch': 0, 'batch': 14, 'loss': 6.838291168212891}\n",
      "{'epoch': 0, 'batch': 15, 'loss': 6.721880912780762}\n",
      "{'epoch': 0, 'batch': 16, 'loss': 6.6384382247924805}\n",
      "{'epoch': 0, 'batch': 17, 'loss': 6.593059539794922}\n",
      "{'epoch': 0, 'batch': 18, 'loss': 6.809497833251953}\n",
      "{'epoch': 0, 'batch': 19, 'loss': 6.577464580535889}\n",
      "{'epoch': 0, 'batch': 20, 'loss': 6.489127159118652}\n",
      "{'epoch': 0, 'batch': 21, 'loss': 6.6720685958862305}\n",
      "{'epoch': 0, 'batch': 22, 'loss': 6.605830669403076}\n",
      "{'epoch': 0, 'batch': 23, 'loss': 6.588760852813721}\n",
      "{'epoch': 0, 'batch': 24, 'loss': 6.6612629890441895}\n",
      "{'epoch': 0, 'batch': 25, 'loss': 6.615544319152832}\n",
      "{'epoch': 0, 'batch': 26, 'loss': 6.785129070281982}\n",
      "{'epoch': 0, 'batch': 27, 'loss': 6.678056240081787}\n",
      "{'epoch': 0, 'batch': 28, 'loss': 6.429802894592285}\n",
      "{'epoch': 0, 'batch': 29, 'loss': 6.663547992706299}\n",
      "{'epoch': 0, 'batch': 30, 'loss': 6.818035125732422}\n",
      "{'epoch': 0, 'batch': 31, 'loss': 6.584469318389893}\n",
      "{'epoch': 0, 'batch': 32, 'loss': 6.432170867919922}\n",
      "{'epoch': 0, 'batch': 33, 'loss': 6.586696147918701}\n",
      "{'epoch': 0, 'batch': 34, 'loss': 6.657731056213379}\n",
      "{'epoch': 0, 'batch': 35, 'loss': 6.697824478149414}\n",
      "{'epoch': 0, 'batch': 36, 'loss': 6.677915573120117}\n",
      "{'epoch': 0, 'batch': 37, 'loss': 6.593217372894287}\n",
      "{'epoch': 0, 'batch': 38, 'loss': 6.604605674743652}\n",
      "{'epoch': 0, 'batch': 39, 'loss': 6.615908622741699}\n",
      "{'epoch': 0, 'batch': 40, 'loss': 6.784096717834473}\n",
      "{'epoch': 0, 'batch': 41, 'loss': 6.696125030517578}\n",
      "{'epoch': 0, 'batch': 42, 'loss': 6.615349292755127}\n",
      "{'epoch': 0, 'batch': 43, 'loss': 6.518133640289307}\n",
      "{'epoch': 0, 'batch': 44, 'loss': 6.635687828063965}\n",
      "{'epoch': 0, 'batch': 45, 'loss': 6.48967170715332}\n",
      "{'epoch': 0, 'batch': 46, 'loss': 6.635623931884766}\n",
      "{'epoch': 0, 'batch': 47, 'loss': 6.52155065536499}\n",
      "{'epoch': 0, 'batch': 48, 'loss': 6.559751033782959}\n",
      "{'epoch': 0, 'batch': 49, 'loss': 6.519672870635986}\n",
      "{'epoch': 0, 'batch': 50, 'loss': 6.5892534255981445}\n",
      "{'epoch': 0, 'batch': 51, 'loss': 6.553485870361328}\n",
      "{'epoch': 0, 'batch': 52, 'loss': 6.6976847648620605}\n",
      "{'epoch': 0, 'batch': 53, 'loss': 6.497095108032227}\n",
      "{'epoch': 0, 'batch': 54, 'loss': 6.735156059265137}\n",
      "{'epoch': 0, 'batch': 55, 'loss': 6.609912395477295}\n",
      "{'epoch': 0, 'batch': 56, 'loss': 6.493027687072754}\n",
      "{'epoch': 0, 'batch': 57, 'loss': 6.555287837982178}\n",
      "{'epoch': 0, 'batch': 58, 'loss': 6.679903507232666}\n",
      "{'epoch': 0, 'batch': 59, 'loss': 6.500725746154785}\n",
      "{'epoch': 0, 'batch': 60, 'loss': 6.445865631103516}\n",
      "{'epoch': 0, 'batch': 61, 'loss': 6.614591598510742}\n",
      "{'epoch': 0, 'batch': 62, 'loss': 6.565962314605713}\n",
      "{'epoch': 0, 'batch': 63, 'loss': 6.53456974029541}\n",
      "{'epoch': 0, 'batch': 64, 'loss': 6.658668518066406}\n",
      "{'epoch': 0, 'batch': 65, 'loss': 6.596468925476074}\n",
      "{'epoch': 0, 'batch': 66, 'loss': 6.626843452453613}\n",
      "{'epoch': 0, 'batch': 67, 'loss': 6.535410404205322}\n",
      "{'epoch': 0, 'batch': 68, 'loss': 6.700700283050537}\n",
      "{'epoch': 0, 'batch': 69, 'loss': 6.489833831787109}\n",
      "{'epoch': 0, 'batch': 70, 'loss': 6.6364312171936035}\n",
      "{'epoch': 0, 'batch': 71, 'loss': 6.541811943054199}\n",
      "{'epoch': 0, 'batch': 72, 'loss': 6.502612590789795}\n",
      "{'epoch': 0, 'batch': 73, 'loss': 6.555408954620361}\n",
      "{'epoch': 0, 'batch': 74, 'loss': 6.586962699890137}\n",
      "{'epoch': 0, 'batch': 75, 'loss': 6.456986427307129}\n",
      "{'epoch': 0, 'batch': 76, 'loss': 6.573026180267334}\n",
      "{'epoch': 0, 'batch': 77, 'loss': 6.51361608505249}\n",
      "{'epoch': 0, 'batch': 78, 'loss': 6.465341091156006}\n",
      "{'epoch': 0, 'batch': 79, 'loss': 6.606684684753418}\n",
      "{'epoch': 0, 'batch': 80, 'loss': 6.606089115142822}\n",
      "{'epoch': 0, 'batch': 81, 'loss': 6.529519081115723}\n",
      "{'epoch': 0, 'batch': 82, 'loss': 6.65470027923584}\n",
      "{'epoch': 0, 'batch': 83, 'loss': 6.560545444488525}\n",
      "{'epoch': 0, 'batch': 84, 'loss': 6.475530624389648}\n",
      "{'epoch': 0, 'batch': 85, 'loss': 6.440704822540283}\n",
      "{'epoch': 0, 'batch': 86, 'loss': 6.566787242889404}\n",
      "{'epoch': 0, 'batch': 87, 'loss': 6.549746990203857}\n",
      "{'epoch': 0, 'batch': 88, 'loss': 6.570091247558594}\n",
      "{'epoch': 0, 'batch': 89, 'loss': 6.555617332458496}\n",
      "{'epoch': 0, 'batch': 90, 'loss': 6.560845375061035}\n",
      "{'epoch': 0, 'batch': 91, 'loss': 6.466516017913818}\n",
      "{'epoch': 0, 'batch': 92, 'loss': 6.578131198883057}\n",
      "{'epoch': 0, 'batch': 93, 'loss': 6.629528045654297}\n",
      "{'epoch': 0, 'batch': 94, 'loss': 6.5948381423950195}\n",
      "{'epoch': 0, 'batch': 95, 'loss': 6.585881233215332}\n",
      "{'epoch': 0, 'batch': 96, 'loss': 6.5717363357543945}\n",
      "{'epoch': 0, 'batch': 97, 'loss': 6.579206943511963}\n",
      "{'epoch': 0, 'batch': 98, 'loss': 6.592898845672607}\n",
      "{'epoch': 0, 'batch': 99, 'loss': 6.532159805297852}\n",
      "{'epoch': 0, 'batch': 100, 'loss': 6.627553939819336}\n",
      "{'epoch': 0, 'batch': 101, 'loss': 6.424402236938477}\n",
      "{'epoch': 0, 'batch': 102, 'loss': 6.64567756652832}\n",
      "{'epoch': 0, 'batch': 103, 'loss': 6.652945041656494}\n",
      "{'epoch': 0, 'batch': 104, 'loss': 6.545751094818115}\n",
      "{'epoch': 0, 'batch': 105, 'loss': 6.583235263824463}\n",
      "{'epoch': 0, 'batch': 106, 'loss': 6.566227436065674}\n",
      "{'epoch': 0, 'batch': 107, 'loss': 6.487800121307373}\n",
      "{'epoch': 0, 'batch': 108, 'loss': 6.485188961029053}\n",
      "{'epoch': 0, 'batch': 109, 'loss': 6.617569446563721}\n",
      "{'epoch': 0, 'batch': 110, 'loss': 6.511696815490723}\n",
      "{'epoch': 0, 'batch': 111, 'loss': 6.540796756744385}\n",
      "{'epoch': 0, 'batch': 112, 'loss': 6.5912699699401855}\n",
      "{'epoch': 0, 'batch': 113, 'loss': 6.435030460357666}\n",
      "{'epoch': 0, 'batch': 114, 'loss': 6.505044937133789}\n",
      "{'epoch': 0, 'batch': 115, 'loss': 6.466343879699707}\n",
      "{'epoch': 0, 'batch': 116, 'loss': 6.600394248962402}\n",
      "{'epoch': 0, 'batch': 117, 'loss': 6.524543285369873}\n",
      "{'epoch': 0, 'batch': 118, 'loss': 6.465526103973389}\n",
      "{'epoch': 0, 'batch': 119, 'loss': 6.455881595611572}\n",
      "{'epoch': 0, 'batch': 120, 'loss': 6.501601219177246}\n",
      "{'epoch': 0, 'batch': 121, 'loss': 6.511446952819824}\n",
      "{'epoch': 0, 'batch': 122, 'loss': 6.69377326965332}\n",
      "{'epoch': 0, 'batch': 123, 'loss': 6.466410160064697}\n",
      "{'epoch': 0, 'batch': 124, 'loss': 6.573144435882568}\n",
      "{'epoch': 0, 'batch': 125, 'loss': 6.556008815765381}\n",
      "{'epoch': 0, 'batch': 126, 'loss': 6.6333699226379395}\n",
      "{'epoch': 0, 'batch': 127, 'loss': 6.521084785461426}\n",
      "{'epoch': 0, 'batch': 128, 'loss': 6.5038275718688965}\n",
      "{'epoch': 0, 'batch': 129, 'loss': 6.632087230682373}\n",
      "{'epoch': 0, 'batch': 130, 'loss': 6.5190300941467285}\n",
      "{'epoch': 0, 'batch': 131, 'loss': 6.5598273277282715}\n",
      "{'epoch': 0, 'batch': 132, 'loss': 6.457179069519043}\n",
      "{'epoch': 0, 'batch': 133, 'loss': 6.41750955581665}\n",
      "{'epoch': 0, 'batch': 134, 'loss': 6.644672393798828}\n",
      "{'epoch': 0, 'batch': 135, 'loss': 6.460843086242676}\n",
      "{'epoch': 0, 'batch': 136, 'loss': 6.523748874664307}\n",
      "{'epoch': 0, 'batch': 137, 'loss': 6.555918216705322}\n",
      "{'epoch': 0, 'batch': 138, 'loss': 6.5248003005981445}\n",
      "{'epoch': 0, 'batch': 139, 'loss': 6.582098007202148}\n",
      "{'epoch': 0, 'batch': 140, 'loss': 6.507668495178223}\n",
      "{'epoch': 0, 'batch': 141, 'loss': 6.668396949768066}\n",
      "{'epoch': 0, 'batch': 142, 'loss': 6.555560111999512}\n",
      "{'epoch': 0, 'batch': 143, 'loss': 6.3779120445251465}\n",
      "{'epoch': 0, 'batch': 144, 'loss': 6.6104655265808105}\n",
      "{'epoch': 0, 'batch': 145, 'loss': 6.459036350250244}\n",
      "{'epoch': 0, 'batch': 146, 'loss': 6.429070949554443}\n",
      "{'epoch': 0, 'batch': 147, 'loss': 6.532930374145508}\n",
      "{'epoch': 0, 'batch': 148, 'loss': 6.4843316078186035}\n",
      "{'epoch': 0, 'batch': 149, 'loss': 6.549710750579834}\n",
      "{'epoch': 0, 'batch': 150, 'loss': 6.587186813354492}\n",
      "{'epoch': 0, 'batch': 151, 'loss': 6.563962459564209}\n",
      "{'epoch': 0, 'batch': 152, 'loss': 6.465578556060791}\n",
      "{'epoch': 0, 'batch': 153, 'loss': 6.55357027053833}\n",
      "{'epoch': 0, 'batch': 154, 'loss': 6.642210483551025}\n",
      "{'epoch': 0, 'batch': 155, 'loss': 6.60105037689209}\n",
      "{'epoch': 0, 'batch': 156, 'loss': 6.467993259429932}\n",
      "{'epoch': 0, 'batch': 157, 'loss': 6.5731520652771}\n",
      "{'epoch': 0, 'batch': 158, 'loss': 6.598896026611328}\n",
      "{'epoch': 0, 'batch': 159, 'loss': 6.5565266609191895}\n",
      "{'epoch': 0, 'batch': 160, 'loss': 6.5539350509643555}\n",
      "{'epoch': 0, 'batch': 161, 'loss': 6.728553295135498}\n",
      "{'epoch': 0, 'batch': 162, 'loss': 6.450302600860596}\n",
      "{'epoch': 0, 'batch': 163, 'loss': 6.639984130859375}\n",
      "{'epoch': 0, 'batch': 164, 'loss': 6.555552959442139}\n",
      "{'epoch': 0, 'batch': 165, 'loss': 6.525747299194336}\n",
      "{'epoch': 0, 'batch': 166, 'loss': 6.489255428314209}\n",
      "{'epoch': 0, 'batch': 167, 'loss': 6.600680351257324}\n",
      "{'epoch': 0, 'batch': 168, 'loss': 6.550997734069824}\n",
      "{'epoch': 0, 'batch': 169, 'loss': 6.516901969909668}\n",
      "{'epoch': 0, 'batch': 170, 'loss': 6.461950778961182}\n",
      "{'epoch': 0, 'batch': 171, 'loss': 6.629451751708984}\n",
      "{'epoch': 0, 'batch': 172, 'loss': 6.506706237792969}\n",
      "{'epoch': 0, 'batch': 173, 'loss': 6.565443992614746}\n",
      "{'epoch': 0, 'batch': 174, 'loss': 6.45462703704834}\n",
      "{'epoch': 0, 'batch': 175, 'loss': 6.426096439361572}\n",
      "{'epoch': 0, 'batch': 176, 'loss': 6.425609588623047}\n",
      "{'epoch': 0, 'batch': 177, 'loss': 6.6625566482543945}\n",
      "{'epoch': 0, 'batch': 178, 'loss': 6.49401330947876}\n",
      "{'epoch': 0, 'batch': 179, 'loss': 6.490837097167969}\n",
      "{'epoch': 0, 'batch': 180, 'loss': 6.524663925170898}\n",
      "{'epoch': 0, 'batch': 181, 'loss': 6.582067489624023}\n",
      "{'epoch': 0, 'batch': 182, 'loss': 6.554923057556152}\n",
      "{'epoch': 0, 'batch': 183, 'loss': 6.584856033325195}\n",
      "{'epoch': 0, 'batch': 184, 'loss': 6.543804168701172}\n",
      "{'epoch': 0, 'batch': 185, 'loss': 6.348595142364502}\n",
      "{'epoch': 0, 'batch': 186, 'loss': 6.596814155578613}\n",
      "{'epoch': 0, 'batch': 187, 'loss': 6.676939010620117}\n",
      "{'epoch': 0, 'batch': 188, 'loss': 6.411938190460205}\n",
      "{'epoch': 0, 'batch': 189, 'loss': 6.502827167510986}\n",
      "{'epoch': 0, 'batch': 190, 'loss': 6.503824234008789}\n",
      "{'epoch': 0, 'batch': 191, 'loss': 6.486001014709473}\n",
      "{'epoch': 0, 'batch': 192, 'loss': 6.462451934814453}\n",
      "{'epoch': 0, 'batch': 193, 'loss': 6.508857727050781}\n",
      "{'epoch': 0, 'batch': 194, 'loss': 6.574603080749512}\n",
      "{'epoch': 0, 'batch': 195, 'loss': 6.647378444671631}\n",
      "{'epoch': 0, 'batch': 196, 'loss': 6.503273963928223}\n",
      "{'epoch': 0, 'batch': 197, 'loss': 6.49153470993042}\n",
      "{'epoch': 0, 'batch': 198, 'loss': 6.5254740715026855}\n",
      "{'epoch': 0, 'batch': 199, 'loss': 6.508247375488281}\n",
      "{'epoch': 0, 'batch': 200, 'loss': 6.522276401519775}\n",
      "{'epoch': 0, 'batch': 201, 'loss': 6.4929656982421875}\n",
      "{'epoch': 0, 'batch': 202, 'loss': 6.597804546356201}\n",
      "{'epoch': 0, 'batch': 203, 'loss': 6.418292045593262}\n",
      "{'epoch': 0, 'batch': 204, 'loss': 6.574102401733398}\n",
      "{'epoch': 0, 'batch': 205, 'loss': 6.401933193206787}\n",
      "{'epoch': 0, 'batch': 206, 'loss': 6.608293533325195}\n",
      "{'epoch': 0, 'batch': 207, 'loss': 6.4638824462890625}\n",
      "{'epoch': 0, 'batch': 208, 'loss': 6.509222030639648}\n",
      "{'epoch': 0, 'batch': 209, 'loss': 6.47869348526001}\n",
      "{'epoch': 0, 'batch': 210, 'loss': 6.463071823120117}\n",
      "{'epoch': 0, 'batch': 211, 'loss': 6.588454723358154}\n",
      "{'epoch': 0, 'batch': 212, 'loss': 6.597316265106201}\n",
      "{'epoch': 0, 'batch': 213, 'loss': 6.4956865310668945}\n",
      "{'epoch': 0, 'batch': 214, 'loss': 6.359477519989014}\n",
      "{'epoch': 0, 'batch': 215, 'loss': 6.398119926452637}\n",
      "{'epoch': 0, 'batch': 216, 'loss': 6.412116050720215}\n",
      "{'epoch': 0, 'batch': 217, 'loss': 6.611420631408691}\n",
      "{'epoch': 0, 'batch': 218, 'loss': 6.493603706359863}\n",
      "{'epoch': 0, 'batch': 219, 'loss': 6.403094291687012}\n",
      "{'epoch': 0, 'batch': 220, 'loss': 6.559318542480469}\n",
      "{'epoch': 0, 'batch': 221, 'loss': 6.441391944885254}\n",
      "{'epoch': 0, 'batch': 222, 'loss': 6.519872188568115}\n",
      "{'epoch': 0, 'batch': 223, 'loss': 6.663527965545654}\n",
      "{'epoch': 0, 'batch': 224, 'loss': 6.451019763946533}\n",
      "{'epoch': 0, 'batch': 225, 'loss': 6.561717987060547}\n",
      "{'epoch': 0, 'batch': 226, 'loss': 6.55374002456665}\n",
      "{'epoch': 0, 'batch': 227, 'loss': 6.523340225219727}\n",
      "{'epoch': 0, 'batch': 228, 'loss': 6.528853893280029}\n",
      "{'epoch': 0, 'batch': 229, 'loss': 6.467955589294434}\n",
      "{'epoch': 0, 'batch': 230, 'loss': 6.500323295593262}\n",
      "{'epoch': 0, 'batch': 231, 'loss': 6.456108093261719}\n",
      "{'epoch': 0, 'batch': 232, 'loss': 6.533495903015137}\n",
      "{'epoch': 0, 'batch': 233, 'loss': 6.459841251373291}\n",
      "{'epoch': 0, 'batch': 234, 'loss': 6.565047264099121}\n",
      "{'epoch': 0, 'batch': 235, 'loss': 6.643928527832031}\n",
      "{'epoch': 0, 'batch': 236, 'loss': 6.532071113586426}\n",
      "{'epoch': 0, 'batch': 237, 'loss': 6.664103984832764}\n",
      "{'epoch': 0, 'batch': 238, 'loss': 6.666308403015137}\n",
      "{'epoch': 0, 'batch': 239, 'loss': 6.374146461486816}\n",
      "{'epoch': 0, 'batch': 240, 'loss': 6.539653778076172}\n",
      "{'epoch': 0, 'batch': 241, 'loss': 6.601635456085205}\n",
      "{'epoch': 0, 'batch': 242, 'loss': 6.551661014556885}\n",
      "{'epoch': 0, 'batch': 243, 'loss': 6.522930145263672}\n",
      "{'epoch': 0, 'batch': 244, 'loss': 6.498924255371094}\n",
      "{'epoch': 0, 'batch': 245, 'loss': 6.549995422363281}\n",
      "{'epoch': 0, 'batch': 246, 'loss': 6.540646553039551}\n",
      "{'epoch': 0, 'batch': 247, 'loss': 6.511119842529297}\n",
      "{'epoch': 0, 'batch': 248, 'loss': 6.5423431396484375}\n",
      "{'epoch': 0, 'batch': 249, 'loss': 6.425962924957275}\n",
      "{'epoch': 0, 'batch': 250, 'loss': 6.5225653648376465}\n",
      "{'epoch': 0, 'batch': 251, 'loss': 6.557332992553711}\n",
      "{'epoch': 0, 'batch': 252, 'loss': 6.589386940002441}\n",
      "{'epoch': 0, 'batch': 253, 'loss': 6.515624046325684}\n",
      "{'epoch': 0, 'batch': 254, 'loss': 6.575447082519531}\n",
      "{'epoch': 0, 'batch': 255, 'loss': 6.563802242279053}\n",
      "{'epoch': 0, 'batch': 256, 'loss': 6.525214195251465}\n",
      "{'epoch': 0, 'batch': 257, 'loss': 6.425869464874268}\n",
      "{'epoch': 0, 'batch': 258, 'loss': 6.609775543212891}\n",
      "{'epoch': 0, 'batch': 259, 'loss': 6.586950302124023}\n",
      "{'epoch': 0, 'batch': 260, 'loss': 6.5224785804748535}\n",
      "{'epoch': 0, 'batch': 261, 'loss': 6.478592872619629}\n",
      "{'epoch': 0, 'batch': 262, 'loss': 6.571773529052734}\n",
      "{'epoch': 0, 'batch': 263, 'loss': 6.610725402832031}\n",
      "{'epoch': 0, 'batch': 264, 'loss': 6.619393825531006}\n",
      "{'epoch': 0, 'batch': 265, 'loss': 6.375056743621826}\n",
      "{'epoch': 0, 'batch': 266, 'loss': 6.541130065917969}\n",
      "{'epoch': 0, 'batch': 267, 'loss': 6.599980354309082}\n",
      "{'epoch': 0, 'batch': 268, 'loss': 6.551172256469727}\n",
      "{'epoch': 0, 'batch': 269, 'loss': 6.409018516540527}\n",
      "{'epoch': 0, 'batch': 270, 'loss': 6.626134395599365}\n",
      "{'epoch': 0, 'batch': 271, 'loss': 6.4599809646606445}\n",
      "{'epoch': 0, 'batch': 272, 'loss': 6.567715644836426}\n",
      "{'epoch': 0, 'batch': 273, 'loss': 6.455075740814209}\n",
      "{'epoch': 0, 'batch': 274, 'loss': 6.625931739807129}\n",
      "{'epoch': 0, 'batch': 275, 'loss': 6.596401691436768}\n",
      "{'epoch': 0, 'batch': 276, 'loss': 6.449399471282959}\n",
      "{'epoch': 0, 'batch': 277, 'loss': 6.444530963897705}\n",
      "{'epoch': 0, 'batch': 278, 'loss': 6.511172294616699}\n",
      "{'epoch': 0, 'batch': 279, 'loss': 6.481274127960205}\n",
      "{'epoch': 0, 'batch': 280, 'loss': 6.611767768859863}\n",
      "{'epoch': 0, 'batch': 281, 'loss': 6.518126964569092}\n",
      "{'epoch': 0, 'batch': 282, 'loss': 6.446696758270264}\n",
      "{'epoch': 0, 'batch': 283, 'loss': 6.5839457511901855}\n",
      "{'epoch': 0, 'batch': 284, 'loss': 6.579721927642822}\n",
      "{'epoch': 0, 'batch': 285, 'loss': 6.4647135734558105}\n",
      "{'epoch': 0, 'batch': 286, 'loss': 6.496992588043213}\n",
      "{'epoch': 0, 'batch': 287, 'loss': 6.45277214050293}\n",
      "{'epoch': 0, 'batch': 288, 'loss': 6.504197597503662}\n",
      "{'epoch': 0, 'batch': 289, 'loss': 6.580428123474121}\n",
      "{'epoch': 0, 'batch': 290, 'loss': 6.748334884643555}\n",
      "{'epoch': 0, 'batch': 291, 'loss': 6.516172409057617}\n",
      "{'epoch': 0, 'batch': 292, 'loss': 6.4903998374938965}\n",
      "{'epoch': 0, 'batch': 293, 'loss': 6.553886413574219}\n",
      "{'epoch': 0, 'batch': 294, 'loss': 6.6411943435668945}\n",
      "{'epoch': 0, 'batch': 295, 'loss': 6.57805871963501}\n",
      "{'epoch': 0, 'batch': 296, 'loss': 6.512178421020508}\n",
      "{'epoch': 0, 'batch': 297, 'loss': 6.5582170486450195}\n",
      "{'epoch': 0, 'batch': 298, 'loss': 6.4740891456604}\n",
      "{'epoch': 0, 'batch': 299, 'loss': 6.513810157775879}\n",
      "{'epoch': 0, 'batch': 300, 'loss': 6.469116687774658}\n",
      "{'epoch': 0, 'batch': 301, 'loss': 6.526918888092041}\n",
      "{'epoch': 0, 'batch': 302, 'loss': 6.564935207366943}\n",
      "{'epoch': 0, 'batch': 303, 'loss': 6.631589412689209}\n",
      "{'epoch': 1, 'batch': 0, 'loss': 6.418608665466309}\n",
      "{'epoch': 1, 'batch': 1, 'loss': 6.451605796813965}\n",
      "{'epoch': 1, 'batch': 2, 'loss': 6.6629157066345215}\n",
      "{'epoch': 1, 'batch': 3, 'loss': 6.6190900802612305}\n",
      "{'epoch': 1, 'batch': 4, 'loss': 6.536797523498535}\n",
      "{'epoch': 1, 'batch': 5, 'loss': 6.457807540893555}\n",
      "{'epoch': 1, 'batch': 6, 'loss': 6.545942306518555}\n",
      "{'epoch': 1, 'batch': 7, 'loss': 6.649592876434326}\n",
      "{'epoch': 1, 'batch': 8, 'loss': 6.433435916900635}\n",
      "{'epoch': 1, 'batch': 9, 'loss': 6.617711544036865}\n",
      "{'epoch': 1, 'batch': 10, 'loss': 6.785487651824951}\n",
      "{'epoch': 1, 'batch': 11, 'loss': 6.553177833557129}\n",
      "{'epoch': 1, 'batch': 12, 'loss': 6.604553699493408}\n",
      "{'epoch': 1, 'batch': 13, 'loss': 6.578657627105713}\n",
      "{'epoch': 1, 'batch': 14, 'loss': 6.585856914520264}\n",
      "{'epoch': 1, 'batch': 15, 'loss': 6.4851813316345215}\n",
      "{'epoch': 1, 'batch': 16, 'loss': 6.541223526000977}\n",
      "{'epoch': 1, 'batch': 17, 'loss': 6.43895959854126}\n",
      "{'epoch': 1, 'batch': 18, 'loss': 6.59177303314209}\n",
      "{'epoch': 1, 'batch': 19, 'loss': 6.523214817047119}\n",
      "{'epoch': 1, 'batch': 20, 'loss': 6.45856237411499}\n",
      "{'epoch': 1, 'batch': 21, 'loss': 6.5412726402282715}\n",
      "{'epoch': 1, 'batch': 22, 'loss': 6.421394348144531}\n",
      "{'epoch': 1, 'batch': 23, 'loss': 6.5367231369018555}\n",
      "{'epoch': 1, 'batch': 24, 'loss': 6.486321449279785}\n",
      "{'epoch': 1, 'batch': 25, 'loss': 6.4771647453308105}\n",
      "{'epoch': 1, 'batch': 26, 'loss': 6.505472660064697}\n",
      "{'epoch': 1, 'batch': 27, 'loss': 6.6166582107543945}\n",
      "{'epoch': 1, 'batch': 28, 'loss': 6.501188278198242}\n",
      "{'epoch': 1, 'batch': 29, 'loss': 6.655184268951416}\n",
      "{'epoch': 1, 'batch': 30, 'loss': 6.477233409881592}\n",
      "{'epoch': 1, 'batch': 31, 'loss': 6.661360740661621}\n",
      "{'epoch': 1, 'batch': 32, 'loss': 6.466859817504883}\n",
      "{'epoch': 1, 'batch': 33, 'loss': 6.567606449127197}\n",
      "{'epoch': 1, 'batch': 34, 'loss': 6.6145501136779785}\n",
      "{'epoch': 1, 'batch': 35, 'loss': 6.405333042144775}\n",
      "{'epoch': 1, 'batch': 36, 'loss': 6.408405303955078}\n",
      "{'epoch': 1, 'batch': 37, 'loss': 6.653141021728516}\n",
      "{'epoch': 1, 'batch': 38, 'loss': 6.603207111358643}\n",
      "{'epoch': 1, 'batch': 39, 'loss': 6.475635051727295}\n",
      "{'epoch': 1, 'batch': 40, 'loss': 6.336735248565674}\n",
      "{'epoch': 1, 'batch': 41, 'loss': 6.388492584228516}\n",
      "{'epoch': 1, 'batch': 42, 'loss': 6.479129314422607}\n",
      "{'epoch': 1, 'batch': 43, 'loss': 6.529946804046631}\n",
      "{'epoch': 1, 'batch': 44, 'loss': 6.530646800994873}\n",
      "{'epoch': 1, 'batch': 45, 'loss': 6.536470413208008}\n",
      "{'epoch': 1, 'batch': 46, 'loss': 6.523560047149658}\n",
      "{'epoch': 1, 'batch': 47, 'loss': 6.48323392868042}\n",
      "{'epoch': 1, 'batch': 48, 'loss': 6.587423801422119}\n",
      "{'epoch': 1, 'batch': 49, 'loss': 6.574578285217285}\n",
      "{'epoch': 1, 'batch': 50, 'loss': 6.489574432373047}\n",
      "{'epoch': 1, 'batch': 51, 'loss': 6.451163291931152}\n",
      "{'epoch': 1, 'batch': 52, 'loss': 6.586793422698975}\n",
      "{'epoch': 1, 'batch': 53, 'loss': 6.459068775177002}\n",
      "{'epoch': 1, 'batch': 54, 'loss': 6.58396577835083}\n",
      "{'epoch': 1, 'batch': 55, 'loss': 6.5546464920043945}\n",
      "{'epoch': 1, 'batch': 56, 'loss': 6.637220859527588}\n",
      "{'epoch': 1, 'batch': 57, 'loss': 6.660638809204102}\n",
      "{'epoch': 1, 'batch': 58, 'loss': 6.605813980102539}\n",
      "{'epoch': 1, 'batch': 59, 'loss': 6.528355598449707}\n",
      "{'epoch': 1, 'batch': 60, 'loss': 6.4446587562561035}\n",
      "{'epoch': 1, 'batch': 61, 'loss': 6.352879524230957}\n",
      "{'epoch': 1, 'batch': 62, 'loss': 6.4310302734375}\n",
      "{'epoch': 1, 'batch': 63, 'loss': 6.518798828125}\n",
      "{'epoch': 1, 'batch': 64, 'loss': 6.642203330993652}\n",
      "{'epoch': 1, 'batch': 65, 'loss': 6.428847312927246}\n",
      "{'epoch': 1, 'batch': 66, 'loss': 6.49425745010376}\n",
      "{'epoch': 1, 'batch': 67, 'loss': 6.621438980102539}\n",
      "{'epoch': 1, 'batch': 68, 'loss': 6.430685043334961}\n",
      "{'epoch': 1, 'batch': 69, 'loss': 6.525172233581543}\n",
      "{'epoch': 1, 'batch': 70, 'loss': 6.551429748535156}\n",
      "{'epoch': 1, 'batch': 71, 'loss': 6.5572285652160645}\n",
      "{'epoch': 1, 'batch': 72, 'loss': 6.4290452003479}\n",
      "{'epoch': 1, 'batch': 73, 'loss': 6.562151908874512}\n",
      "{'epoch': 1, 'batch': 74, 'loss': 6.503994464874268}\n",
      "{'epoch': 1, 'batch': 75, 'loss': 6.4891886711120605}\n",
      "{'epoch': 1, 'batch': 76, 'loss': 6.540305137634277}\n",
      "{'epoch': 1, 'batch': 77, 'loss': 6.573526382446289}\n",
      "{'epoch': 1, 'batch': 78, 'loss': 6.479278087615967}\n",
      "{'epoch': 1, 'batch': 79, 'loss': 6.520328044891357}\n",
      "{'epoch': 1, 'batch': 80, 'loss': 6.467180252075195}\n",
      "{'epoch': 1, 'batch': 81, 'loss': 6.625061511993408}\n",
      "{'epoch': 1, 'batch': 82, 'loss': 6.527605056762695}\n",
      "{'epoch': 1, 'batch': 83, 'loss': 6.4316606521606445}\n",
      "{'epoch': 1, 'batch': 84, 'loss': 6.444026947021484}\n",
      "{'epoch': 1, 'batch': 85, 'loss': 6.655367851257324}\n",
      "{'epoch': 1, 'batch': 86, 'loss': 6.439009189605713}\n",
      "{'epoch': 1, 'batch': 87, 'loss': 6.376084804534912}\n",
      "{'epoch': 1, 'batch': 88, 'loss': 6.571250915527344}\n",
      "{'epoch': 1, 'batch': 89, 'loss': 6.468892574310303}\n",
      "{'epoch': 1, 'batch': 90, 'loss': 6.690146446228027}\n",
      "{'epoch': 1, 'batch': 91, 'loss': 6.542632102966309}\n",
      "{'epoch': 1, 'batch': 92, 'loss': 6.5543107986450195}\n",
      "{'epoch': 1, 'batch': 93, 'loss': 6.514738082885742}\n",
      "{'epoch': 1, 'batch': 94, 'loss': 6.522555828094482}\n",
      "{'epoch': 1, 'batch': 95, 'loss': 6.58133602142334}\n",
      "{'epoch': 1, 'batch': 96, 'loss': 6.3850483894348145}\n",
      "{'epoch': 1, 'batch': 97, 'loss': 6.450516700744629}\n",
      "{'epoch': 1, 'batch': 98, 'loss': 6.446343421936035}\n",
      "{'epoch': 1, 'batch': 99, 'loss': 6.3925371170043945}\n",
      "{'epoch': 1, 'batch': 100, 'loss': 6.45203161239624}\n",
      "{'epoch': 1, 'batch': 101, 'loss': 6.529769420623779}\n",
      "{'epoch': 1, 'batch': 102, 'loss': 6.594179630279541}\n",
      "{'epoch': 1, 'batch': 103, 'loss': 6.624744415283203}\n",
      "{'epoch': 1, 'batch': 104, 'loss': 6.614394187927246}\n",
      "{'epoch': 1, 'batch': 105, 'loss': 6.580056190490723}\n",
      "{'epoch': 1, 'batch': 106, 'loss': 6.507174491882324}\n",
      "{'epoch': 1, 'batch': 107, 'loss': 6.632755756378174}\n",
      "{'epoch': 1, 'batch': 108, 'loss': 6.59410285949707}\n",
      "{'epoch': 1, 'batch': 109, 'loss': 6.479427814483643}\n",
      "{'epoch': 1, 'batch': 110, 'loss': 6.459359169006348}\n",
      "{'epoch': 1, 'batch': 111, 'loss': 6.3863983154296875}\n",
      "{'epoch': 1, 'batch': 112, 'loss': 6.475992202758789}\n",
      "{'epoch': 1, 'batch': 113, 'loss': 6.506375789642334}\n",
      "{'epoch': 1, 'batch': 114, 'loss': 6.52325963973999}\n",
      "{'epoch': 1, 'batch': 115, 'loss': 6.419238567352295}\n",
      "{'epoch': 1, 'batch': 116, 'loss': 6.542547702789307}\n",
      "{'epoch': 1, 'batch': 117, 'loss': 6.355572700500488}\n",
      "{'epoch': 1, 'batch': 118, 'loss': 6.552243232727051}\n",
      "{'epoch': 1, 'batch': 119, 'loss': 6.514424800872803}\n",
      "{'epoch': 1, 'batch': 120, 'loss': 6.521461009979248}\n",
      "{'epoch': 1, 'batch': 121, 'loss': 6.462592124938965}\n",
      "{'epoch': 1, 'batch': 122, 'loss': 6.319085121154785}\n",
      "{'epoch': 1, 'batch': 123, 'loss': 6.4454216957092285}\n",
      "{'epoch': 1, 'batch': 124, 'loss': 6.42295503616333}\n",
      "{'epoch': 1, 'batch': 125, 'loss': 6.429266452789307}\n",
      "{'epoch': 1, 'batch': 126, 'loss': 6.477441787719727}\n",
      "{'epoch': 1, 'batch': 127, 'loss': 6.528537750244141}\n",
      "{'epoch': 1, 'batch': 128, 'loss': 6.45963191986084}\n",
      "{'epoch': 1, 'batch': 129, 'loss': 6.505634307861328}\n",
      "{'epoch': 1, 'batch': 130, 'loss': 6.50348424911499}\n",
      "{'epoch': 1, 'batch': 131, 'loss': 6.401582717895508}\n",
      "{'epoch': 1, 'batch': 132, 'loss': 6.495935440063477}\n",
      "{'epoch': 1, 'batch': 133, 'loss': 6.581465721130371}\n",
      "{'epoch': 1, 'batch': 134, 'loss': 6.356544017791748}\n",
      "{'epoch': 1, 'batch': 135, 'loss': 6.626322269439697}\n",
      "{'epoch': 1, 'batch': 136, 'loss': 6.468023300170898}\n",
      "{'epoch': 1, 'batch': 137, 'loss': 6.512612819671631}\n",
      "{'epoch': 1, 'batch': 138, 'loss': 6.53101110458374}\n",
      "{'epoch': 1, 'batch': 139, 'loss': 6.515313625335693}\n",
      "{'epoch': 1, 'batch': 140, 'loss': 6.351404190063477}\n",
      "{'epoch': 1, 'batch': 141, 'loss': 6.4926652908325195}\n",
      "{'epoch': 1, 'batch': 142, 'loss': 6.296443939208984}\n",
      "{'epoch': 1, 'batch': 143, 'loss': 6.503954887390137}\n",
      "{'epoch': 1, 'batch': 144, 'loss': 6.533985614776611}\n",
      "{'epoch': 1, 'batch': 145, 'loss': 6.421356678009033}\n",
      "{'epoch': 1, 'batch': 146, 'loss': 6.322483062744141}\n",
      "{'epoch': 1, 'batch': 147, 'loss': 6.301366806030273}\n",
      "{'epoch': 1, 'batch': 148, 'loss': 6.392210483551025}\n",
      "{'epoch': 1, 'batch': 149, 'loss': 6.428639888763428}\n",
      "{'epoch': 1, 'batch': 150, 'loss': 6.346183776855469}\n",
      "{'epoch': 1, 'batch': 151, 'loss': 6.36644983291626}\n",
      "{'epoch': 1, 'batch': 152, 'loss': 6.435085773468018}\n",
      "{'epoch': 1, 'batch': 153, 'loss': 6.432543754577637}\n",
      "{'epoch': 1, 'batch': 154, 'loss': 6.4831647872924805}\n",
      "{'epoch': 1, 'batch': 155, 'loss': 6.390932083129883}\n",
      "{'epoch': 1, 'batch': 156, 'loss': 6.51657772064209}\n",
      "{'epoch': 1, 'batch': 157, 'loss': 6.406982898712158}\n",
      "{'epoch': 1, 'batch': 158, 'loss': 6.357990264892578}\n",
      "{'epoch': 1, 'batch': 159, 'loss': 6.404175281524658}\n",
      "{'epoch': 1, 'batch': 160, 'loss': 6.463298797607422}\n",
      "{'epoch': 1, 'batch': 161, 'loss': 6.5229973793029785}\n",
      "{'epoch': 1, 'batch': 162, 'loss': 6.341449737548828}\n",
      "{'epoch': 1, 'batch': 163, 'loss': 6.432224750518799}\n",
      "{'epoch': 1, 'batch': 164, 'loss': 6.474102020263672}\n",
      "{'epoch': 1, 'batch': 165, 'loss': 6.2793169021606445}\n",
      "{'epoch': 1, 'batch': 166, 'loss': 6.552140235900879}\n",
      "{'epoch': 1, 'batch': 167, 'loss': 6.399628162384033}\n",
      "{'epoch': 1, 'batch': 168, 'loss': 6.346746444702148}\n",
      "{'epoch': 1, 'batch': 169, 'loss': 6.567673206329346}\n",
      "{'epoch': 1, 'batch': 170, 'loss': 6.494498252868652}\n",
      "{'epoch': 1, 'batch': 171, 'loss': 6.54951286315918}\n",
      "{'epoch': 1, 'batch': 172, 'loss': 6.458492279052734}\n",
      "{'epoch': 1, 'batch': 173, 'loss': 6.4153947830200195}\n",
      "{'epoch': 1, 'batch': 174, 'loss': 6.408507347106934}\n",
      "{'epoch': 1, 'batch': 175, 'loss': 6.504521369934082}\n",
      "{'epoch': 1, 'batch': 176, 'loss': 6.35590124130249}\n",
      "{'epoch': 1, 'batch': 177, 'loss': 6.372344493865967}\n",
      "{'epoch': 1, 'batch': 178, 'loss': 6.474844932556152}\n",
      "{'epoch': 1, 'batch': 179, 'loss': 6.456146240234375}\n",
      "{'epoch': 1, 'batch': 180, 'loss': 6.512393951416016}\n",
      "{'epoch': 1, 'batch': 181, 'loss': 6.340292930603027}\n",
      "{'epoch': 1, 'batch': 182, 'loss': 6.304013252258301}\n",
      "{'epoch': 1, 'batch': 183, 'loss': 6.347175598144531}\n",
      "{'epoch': 1, 'batch': 184, 'loss': 6.504362106323242}\n",
      "{'epoch': 1, 'batch': 185, 'loss': 6.511749267578125}\n",
      "{'epoch': 1, 'batch': 186, 'loss': 6.483766555786133}\n",
      "{'epoch': 1, 'batch': 187, 'loss': 6.417119979858398}\n",
      "{'epoch': 1, 'batch': 188, 'loss': 6.326039791107178}\n",
      "{'epoch': 1, 'batch': 189, 'loss': 6.398009777069092}\n",
      "{'epoch': 1, 'batch': 190, 'loss': 6.355031967163086}\n",
      "{'epoch': 1, 'batch': 191, 'loss': 6.369551181793213}\n",
      "{'epoch': 1, 'batch': 192, 'loss': 6.385708808898926}\n",
      "{'epoch': 1, 'batch': 193, 'loss': 6.347588539123535}\n",
      "{'epoch': 1, 'batch': 194, 'loss': 6.397889614105225}\n",
      "{'epoch': 1, 'batch': 195, 'loss': 6.29718542098999}\n",
      "{'epoch': 1, 'batch': 196, 'loss': 6.396731376647949}\n",
      "{'epoch': 1, 'batch': 197, 'loss': 6.469155311584473}\n",
      "{'epoch': 1, 'batch': 198, 'loss': 6.475900173187256}\n",
      "{'epoch': 1, 'batch': 199, 'loss': 6.521079063415527}\n",
      "{'epoch': 1, 'batch': 200, 'loss': 6.362907886505127}\n",
      "{'epoch': 1, 'batch': 201, 'loss': 6.314935684204102}\n",
      "{'epoch': 1, 'batch': 202, 'loss': 6.343369007110596}\n",
      "{'epoch': 1, 'batch': 203, 'loss': 6.380828857421875}\n",
      "{'epoch': 1, 'batch': 204, 'loss': 6.412107944488525}\n",
      "{'epoch': 1, 'batch': 205, 'loss': 6.420535564422607}\n",
      "{'epoch': 1, 'batch': 206, 'loss': 6.4412126541137695}\n",
      "{'epoch': 1, 'batch': 207, 'loss': 6.3210062980651855}\n",
      "{'epoch': 1, 'batch': 208, 'loss': 6.420022487640381}\n",
      "{'epoch': 1, 'batch': 209, 'loss': 6.408108234405518}\n",
      "{'epoch': 1, 'batch': 210, 'loss': 6.3140482902526855}\n",
      "{'epoch': 1, 'batch': 211, 'loss': 6.292720317840576}\n",
      "{'epoch': 1, 'batch': 212, 'loss': 6.359440803527832}\n",
      "{'epoch': 1, 'batch': 213, 'loss': 6.466538906097412}\n",
      "{'epoch': 1, 'batch': 214, 'loss': 6.29399299621582}\n",
      "{'epoch': 1, 'batch': 215, 'loss': 6.35636043548584}\n",
      "{'epoch': 1, 'batch': 216, 'loss': 6.376290798187256}\n",
      "{'epoch': 1, 'batch': 217, 'loss': 6.346893310546875}\n",
      "{'epoch': 1, 'batch': 218, 'loss': 6.441032409667969}\n",
      "{'epoch': 1, 'batch': 219, 'loss': 6.391596794128418}\n",
      "{'epoch': 1, 'batch': 220, 'loss': 6.302143573760986}\n",
      "{'epoch': 1, 'batch': 221, 'loss': 6.429337501525879}\n",
      "{'epoch': 1, 'batch': 222, 'loss': 6.314974784851074}\n",
      "{'epoch': 1, 'batch': 223, 'loss': 6.2919158935546875}\n",
      "{'epoch': 1, 'batch': 224, 'loss': 6.353048801422119}\n",
      "{'epoch': 1, 'batch': 225, 'loss': 6.364092826843262}\n",
      "{'epoch': 1, 'batch': 226, 'loss': 6.459092617034912}\n",
      "{'epoch': 1, 'batch': 227, 'loss': 6.41412353515625}\n",
      "{'epoch': 1, 'batch': 228, 'loss': 6.420228958129883}\n",
      "{'epoch': 1, 'batch': 229, 'loss': 6.3989338874816895}\n",
      "{'epoch': 1, 'batch': 230, 'loss': 6.300557613372803}\n",
      "{'epoch': 1, 'batch': 231, 'loss': 6.270208835601807}\n",
      "{'epoch': 1, 'batch': 232, 'loss': 6.409643650054932}\n",
      "{'epoch': 1, 'batch': 233, 'loss': 6.497276306152344}\n",
      "{'epoch': 1, 'batch': 234, 'loss': 6.3315558433532715}\n",
      "{'epoch': 1, 'batch': 235, 'loss': 6.391340255737305}\n",
      "{'epoch': 1, 'batch': 236, 'loss': 6.432527542114258}\n",
      "{'epoch': 1, 'batch': 237, 'loss': 6.384728908538818}\n",
      "{'epoch': 1, 'batch': 238, 'loss': 6.331009387969971}\n",
      "{'epoch': 1, 'batch': 239, 'loss': 6.267561435699463}\n",
      "{'epoch': 1, 'batch': 240, 'loss': 6.295365810394287}\n",
      "{'epoch': 1, 'batch': 241, 'loss': 6.238132953643799}\n",
      "{'epoch': 1, 'batch': 242, 'loss': 6.4233479499816895}\n",
      "{'epoch': 1, 'batch': 243, 'loss': 6.27869987487793}\n",
      "{'epoch': 1, 'batch': 244, 'loss': 6.42665433883667}\n",
      "{'epoch': 1, 'batch': 245, 'loss': 6.330345153808594}\n",
      "{'epoch': 1, 'batch': 246, 'loss': 6.408514976501465}\n",
      "{'epoch': 1, 'batch': 247, 'loss': 6.577774524688721}\n",
      "{'epoch': 1, 'batch': 248, 'loss': 6.4235100746154785}\n",
      "{'epoch': 1, 'batch': 249, 'loss': 6.243671894073486}\n",
      "{'epoch': 1, 'batch': 250, 'loss': 6.253584861755371}\n",
      "{'epoch': 1, 'batch': 251, 'loss': 6.360872268676758}\n",
      "{'epoch': 1, 'batch': 252, 'loss': 6.485879421234131}\n",
      "{'epoch': 1, 'batch': 253, 'loss': 6.42770528793335}\n",
      "{'epoch': 1, 'batch': 254, 'loss': 6.334225654602051}\n",
      "{'epoch': 1, 'batch': 255, 'loss': 6.3332414627075195}\n",
      "{'epoch': 1, 'batch': 256, 'loss': 6.275957107543945}\n",
      "{'epoch': 1, 'batch': 257, 'loss': 6.33237886428833}\n",
      "{'epoch': 1, 'batch': 258, 'loss': 6.322005271911621}\n",
      "{'epoch': 1, 'batch': 259, 'loss': 6.243511199951172}\n",
      "{'epoch': 1, 'batch': 260, 'loss': 6.558917999267578}\n",
      "{'epoch': 1, 'batch': 261, 'loss': 6.214390754699707}\n",
      "{'epoch': 1, 'batch': 262, 'loss': 6.337794303894043}\n",
      "{'epoch': 1, 'batch': 263, 'loss': 6.416815280914307}\n",
      "{'epoch': 1, 'batch': 264, 'loss': 6.3139848709106445}\n",
      "{'epoch': 1, 'batch': 265, 'loss': 6.343161582946777}\n",
      "{'epoch': 1, 'batch': 266, 'loss': 6.245296478271484}\n",
      "{'epoch': 1, 'batch': 267, 'loss': 6.281839847564697}\n",
      "{'epoch': 1, 'batch': 268, 'loss': 6.316529750823975}\n",
      "{'epoch': 1, 'batch': 269, 'loss': 6.285635948181152}\n",
      "{'epoch': 1, 'batch': 270, 'loss': 6.326362609863281}\n",
      "{'epoch': 1, 'batch': 271, 'loss': 6.334462642669678}\n",
      "{'epoch': 1, 'batch': 272, 'loss': 6.384145736694336}\n",
      "{'epoch': 1, 'batch': 273, 'loss': 6.298636436462402}\n",
      "{'epoch': 1, 'batch': 274, 'loss': 6.423930644989014}\n",
      "{'epoch': 1, 'batch': 275, 'loss': 6.222934722900391}\n",
      "{'epoch': 1, 'batch': 276, 'loss': 6.419672012329102}\n",
      "{'epoch': 1, 'batch': 277, 'loss': 6.282961368560791}\n",
      "{'epoch': 1, 'batch': 278, 'loss': 6.3614068031311035}\n",
      "{'epoch': 1, 'batch': 279, 'loss': 6.250696659088135}\n",
      "{'epoch': 1, 'batch': 280, 'loss': 6.31156587600708}\n",
      "{'epoch': 1, 'batch': 281, 'loss': 6.352103233337402}\n",
      "{'epoch': 1, 'batch': 282, 'loss': 6.3904924392700195}\n",
      "{'epoch': 1, 'batch': 283, 'loss': 6.323122501373291}\n",
      "{'epoch': 1, 'batch': 284, 'loss': 6.329363822937012}\n",
      "{'epoch': 1, 'batch': 285, 'loss': 6.166009426116943}\n",
      "{'epoch': 1, 'batch': 286, 'loss': 6.346416473388672}\n",
      "{'epoch': 1, 'batch': 287, 'loss': 6.298154354095459}\n",
      "{'epoch': 1, 'batch': 288, 'loss': 6.263089179992676}\n",
      "{'epoch': 1, 'batch': 289, 'loss': 6.346582412719727}\n",
      "{'epoch': 1, 'batch': 290, 'loss': 6.476555824279785}\n",
      "{'epoch': 1, 'batch': 291, 'loss': 6.433788776397705}\n",
      "{'epoch': 1, 'batch': 292, 'loss': 6.293232440948486}\n",
      "{'epoch': 1, 'batch': 293, 'loss': 6.4670820236206055}\n",
      "{'epoch': 1, 'batch': 294, 'loss': 6.422816276550293}\n",
      "{'epoch': 1, 'batch': 295, 'loss': 6.304335594177246}\n",
      "{'epoch': 1, 'batch': 296, 'loss': 6.286307334899902}\n",
      "{'epoch': 1, 'batch': 297, 'loss': 6.278940677642822}\n",
      "{'epoch': 1, 'batch': 298, 'loss': 6.356592655181885}\n",
      "{'epoch': 1, 'batch': 299, 'loss': 6.255101680755615}\n",
      "{'epoch': 1, 'batch': 300, 'loss': 6.336170196533203}\n",
      "{'epoch': 1, 'batch': 301, 'loss': 6.312101364135742}\n",
      "{'epoch': 1, 'batch': 302, 'loss': 6.29561710357666}\n",
      "{'epoch': 1, 'batch': 303, 'loss': 6.2972025871276855}\n",
      "{'epoch': 2, 'batch': 0, 'loss': 6.234720230102539}\n",
      "{'epoch': 2, 'batch': 1, 'loss': 6.107972145080566}\n",
      "{'epoch': 2, 'batch': 2, 'loss': 6.247410774230957}\n",
      "{'epoch': 2, 'batch': 3, 'loss': 6.259232044219971}\n",
      "{'epoch': 2, 'batch': 4, 'loss': 6.324706554412842}\n",
      "{'epoch': 2, 'batch': 5, 'loss': 6.292291164398193}\n",
      "{'epoch': 2, 'batch': 6, 'loss': 6.357208251953125}\n",
      "{'epoch': 2, 'batch': 7, 'loss': 6.428711414337158}\n",
      "{'epoch': 2, 'batch': 8, 'loss': 6.3253493309021}\n",
      "{'epoch': 2, 'batch': 9, 'loss': 6.227272033691406}\n",
      "{'epoch': 2, 'batch': 10, 'loss': 6.2845964431762695}\n",
      "{'epoch': 2, 'batch': 11, 'loss': 6.362741947174072}\n",
      "{'epoch': 2, 'batch': 12, 'loss': 6.404414653778076}\n",
      "{'epoch': 2, 'batch': 13, 'loss': 6.312680244445801}\n",
      "{'epoch': 2, 'batch': 14, 'loss': 6.277637004852295}\n",
      "{'epoch': 2, 'batch': 15, 'loss': 6.224507808685303}\n",
      "{'epoch': 2, 'batch': 16, 'loss': 6.2755632400512695}\n",
      "{'epoch': 2, 'batch': 17, 'loss': 6.285443305969238}\n",
      "{'epoch': 2, 'batch': 18, 'loss': 6.416347980499268}\n",
      "{'epoch': 2, 'batch': 19, 'loss': 6.272955417633057}\n",
      "{'epoch': 2, 'batch': 20, 'loss': 6.3804497718811035}\n",
      "{'epoch': 2, 'batch': 21, 'loss': 6.370488166809082}\n",
      "{'epoch': 2, 'batch': 22, 'loss': 6.19711446762085}\n",
      "{'epoch': 2, 'batch': 23, 'loss': 6.239207744598389}\n",
      "{'epoch': 2, 'batch': 24, 'loss': 6.268199920654297}\n",
      "{'epoch': 2, 'batch': 25, 'loss': 6.236649513244629}\n",
      "{'epoch': 2, 'batch': 26, 'loss': 6.249360084533691}\n",
      "{'epoch': 2, 'batch': 27, 'loss': 6.307283401489258}\n",
      "{'epoch': 2, 'batch': 28, 'loss': 6.325011730194092}\n",
      "{'epoch': 2, 'batch': 29, 'loss': 6.293654918670654}\n",
      "{'epoch': 2, 'batch': 30, 'loss': 6.207057952880859}\n",
      "{'epoch': 2, 'batch': 31, 'loss': 6.325401782989502}\n",
      "{'epoch': 2, 'batch': 32, 'loss': 6.360793113708496}\n",
      "{'epoch': 2, 'batch': 33, 'loss': 6.406769275665283}\n",
      "{'epoch': 2, 'batch': 34, 'loss': 6.246486663818359}\n",
      "{'epoch': 2, 'batch': 35, 'loss': 6.365910053253174}\n",
      "{'epoch': 2, 'batch': 36, 'loss': 6.263561248779297}\n",
      "{'epoch': 2, 'batch': 37, 'loss': 6.316113471984863}\n",
      "{'epoch': 2, 'batch': 38, 'loss': 6.1635308265686035}\n",
      "{'epoch': 2, 'batch': 39, 'loss': 6.266077518463135}\n",
      "{'epoch': 2, 'batch': 40, 'loss': 6.261340618133545}\n",
      "{'epoch': 2, 'batch': 41, 'loss': 6.3626275062561035}\n",
      "{'epoch': 2, 'batch': 42, 'loss': 6.360987186431885}\n",
      "{'epoch': 2, 'batch': 43, 'loss': 6.188873291015625}\n",
      "{'epoch': 2, 'batch': 44, 'loss': 6.195744514465332}\n",
      "{'epoch': 2, 'batch': 45, 'loss': 6.380346298217773}\n",
      "{'epoch': 2, 'batch': 46, 'loss': 6.501204013824463}\n",
      "{'epoch': 2, 'batch': 47, 'loss': 6.196460247039795}\n",
      "{'epoch': 2, 'batch': 48, 'loss': 6.191439628601074}\n",
      "{'epoch': 2, 'batch': 49, 'loss': 6.278616428375244}\n",
      "{'epoch': 2, 'batch': 50, 'loss': 6.234763145446777}\n",
      "{'epoch': 2, 'batch': 51, 'loss': 6.208633899688721}\n",
      "{'epoch': 2, 'batch': 52, 'loss': 6.2797698974609375}\n",
      "{'epoch': 2, 'batch': 53, 'loss': 6.250674247741699}\n",
      "{'epoch': 2, 'batch': 54, 'loss': 6.2110595703125}\n",
      "{'epoch': 2, 'batch': 55, 'loss': 6.233016490936279}\n",
      "{'epoch': 2, 'batch': 56, 'loss': 6.218570232391357}\n",
      "{'epoch': 2, 'batch': 57, 'loss': 6.235728740692139}\n",
      "{'epoch': 2, 'batch': 58, 'loss': 6.318761825561523}\n",
      "{'epoch': 2, 'batch': 59, 'loss': 6.331130504608154}\n",
      "{'epoch': 2, 'batch': 60, 'loss': 6.275505065917969}\n",
      "{'epoch': 2, 'batch': 61, 'loss': 6.310449600219727}\n",
      "{'epoch': 2, 'batch': 62, 'loss': 6.259747505187988}\n",
      "{'epoch': 2, 'batch': 63, 'loss': 6.29585075378418}\n",
      "{'epoch': 2, 'batch': 64, 'loss': 6.18710994720459}\n",
      "{'epoch': 2, 'batch': 65, 'loss': 6.200934410095215}\n",
      "{'epoch': 2, 'batch': 66, 'loss': 6.2740559577941895}\n",
      "{'epoch': 2, 'batch': 67, 'loss': 6.2202863693237305}\n",
      "{'epoch': 2, 'batch': 68, 'loss': 6.361043453216553}\n",
      "{'epoch': 2, 'batch': 69, 'loss': 6.304971218109131}\n",
      "{'epoch': 2, 'batch': 70, 'loss': 6.197591781616211}\n",
      "{'epoch': 2, 'batch': 71, 'loss': 6.235538959503174}\n",
      "{'epoch': 2, 'batch': 72, 'loss': 6.302907943725586}\n",
      "{'epoch': 2, 'batch': 73, 'loss': 6.231010913848877}\n",
      "{'epoch': 2, 'batch': 74, 'loss': 6.180545806884766}\n",
      "{'epoch': 2, 'batch': 75, 'loss': 6.2954301834106445}\n",
      "{'epoch': 2, 'batch': 76, 'loss': 6.223317623138428}\n",
      "{'epoch': 2, 'batch': 77, 'loss': 6.242132663726807}\n",
      "{'epoch': 2, 'batch': 78, 'loss': 6.220111846923828}\n",
      "{'epoch': 2, 'batch': 79, 'loss': 6.2457427978515625}\n",
      "{'epoch': 2, 'batch': 80, 'loss': 6.19736385345459}\n",
      "{'epoch': 2, 'batch': 81, 'loss': 6.185454368591309}\n",
      "{'epoch': 2, 'batch': 82, 'loss': 6.226761817932129}\n",
      "{'epoch': 2, 'batch': 83, 'loss': 6.2916951179504395}\n",
      "{'epoch': 2, 'batch': 84, 'loss': 6.2166314125061035}\n",
      "{'epoch': 2, 'batch': 85, 'loss': 6.194609642028809}\n",
      "{'epoch': 2, 'batch': 86, 'loss': 6.272911548614502}\n",
      "{'epoch': 2, 'batch': 87, 'loss': 6.271965026855469}\n",
      "{'epoch': 2, 'batch': 88, 'loss': 6.119892120361328}\n",
      "{'epoch': 2, 'batch': 89, 'loss': 6.289549350738525}\n",
      "{'epoch': 2, 'batch': 90, 'loss': 6.181309700012207}\n",
      "{'epoch': 2, 'batch': 91, 'loss': 6.273116111755371}\n",
      "{'epoch': 2, 'batch': 92, 'loss': 6.156508922576904}\n",
      "{'epoch': 2, 'batch': 93, 'loss': 6.194474697113037}\n",
      "{'epoch': 2, 'batch': 94, 'loss': 6.126819610595703}\n",
      "{'epoch': 2, 'batch': 95, 'loss': 6.264819622039795}\n",
      "{'epoch': 2, 'batch': 96, 'loss': 6.220679759979248}\n",
      "{'epoch': 2, 'batch': 97, 'loss': 6.188365459442139}\n",
      "{'epoch': 2, 'batch': 98, 'loss': 6.199449062347412}\n",
      "{'epoch': 2, 'batch': 99, 'loss': 6.351932048797607}\n",
      "{'epoch': 2, 'batch': 100, 'loss': 6.104074001312256}\n",
      "{'epoch': 2, 'batch': 101, 'loss': 6.109376907348633}\n",
      "{'epoch': 2, 'batch': 102, 'loss': 6.160866737365723}\n",
      "{'epoch': 2, 'batch': 103, 'loss': 6.2010626792907715}\n",
      "{'epoch': 2, 'batch': 104, 'loss': 6.150708198547363}\n",
      "{'epoch': 2, 'batch': 105, 'loss': 6.282623291015625}\n",
      "{'epoch': 2, 'batch': 106, 'loss': 6.385109901428223}\n",
      "{'epoch': 2, 'batch': 107, 'loss': 6.320704936981201}\n",
      "{'epoch': 2, 'batch': 108, 'loss': 6.0107102394104}\n",
      "{'epoch': 2, 'batch': 109, 'loss': 6.139789581298828}\n",
      "{'epoch': 2, 'batch': 110, 'loss': 6.206714630126953}\n",
      "{'epoch': 2, 'batch': 111, 'loss': 6.257359981536865}\n",
      "{'epoch': 2, 'batch': 112, 'loss': 6.129690170288086}\n",
      "{'epoch': 2, 'batch': 113, 'loss': 6.3342814445495605}\n",
      "{'epoch': 2, 'batch': 114, 'loss': 6.311310768127441}\n",
      "{'epoch': 2, 'batch': 115, 'loss': 6.318753242492676}\n",
      "{'epoch': 2, 'batch': 116, 'loss': 6.2972893714904785}\n",
      "{'epoch': 2, 'batch': 117, 'loss': 6.038847923278809}\n",
      "{'epoch': 2, 'batch': 118, 'loss': 6.123219013214111}\n",
      "{'epoch': 2, 'batch': 119, 'loss': 6.154648780822754}\n",
      "{'epoch': 2, 'batch': 120, 'loss': 6.205636978149414}\n",
      "{'epoch': 2, 'batch': 121, 'loss': 6.117977142333984}\n",
      "{'epoch': 2, 'batch': 122, 'loss': 6.177738189697266}\n",
      "{'epoch': 2, 'batch': 123, 'loss': 6.201910495758057}\n",
      "{'epoch': 2, 'batch': 124, 'loss': 6.132778644561768}\n",
      "{'epoch': 2, 'batch': 125, 'loss': 6.140120029449463}\n",
      "{'epoch': 2, 'batch': 126, 'loss': 6.1525115966796875}\n",
      "{'epoch': 2, 'batch': 127, 'loss': 6.336277008056641}\n",
      "{'epoch': 2, 'batch': 128, 'loss': 6.1351542472839355}\n",
      "{'epoch': 2, 'batch': 129, 'loss': 6.157284259796143}\n",
      "{'epoch': 2, 'batch': 130, 'loss': 6.055161952972412}\n",
      "{'epoch': 2, 'batch': 131, 'loss': 6.205925941467285}\n",
      "{'epoch': 2, 'batch': 132, 'loss': 6.0626630783081055}\n",
      "{'epoch': 2, 'batch': 133, 'loss': 6.103118896484375}\n",
      "{'epoch': 2, 'batch': 134, 'loss': 6.077034950256348}\n",
      "{'epoch': 2, 'batch': 135, 'loss': 6.141748428344727}\n",
      "{'epoch': 2, 'batch': 136, 'loss': 6.128842830657959}\n",
      "{'epoch': 2, 'batch': 137, 'loss': 6.028328895568848}\n",
      "{'epoch': 2, 'batch': 138, 'loss': 6.2207207679748535}\n",
      "{'epoch': 2, 'batch': 139, 'loss': 6.07590389251709}\n",
      "{'epoch': 2, 'batch': 140, 'loss': 6.208136558532715}\n",
      "{'epoch': 2, 'batch': 141, 'loss': 6.145453453063965}\n",
      "{'epoch': 2, 'batch': 142, 'loss': 6.270351886749268}\n",
      "{'epoch': 2, 'batch': 143, 'loss': 6.1439924240112305}\n",
      "{'epoch': 2, 'batch': 144, 'loss': 6.0461883544921875}\n",
      "{'epoch': 2, 'batch': 145, 'loss': 6.04652214050293}\n",
      "{'epoch': 2, 'batch': 146, 'loss': 6.088262557983398}\n",
      "{'epoch': 2, 'batch': 147, 'loss': 6.085888862609863}\n",
      "{'epoch': 2, 'batch': 148, 'loss': 6.268648147583008}\n",
      "{'epoch': 2, 'batch': 149, 'loss': 6.143655300140381}\n",
      "{'epoch': 2, 'batch': 150, 'loss': 6.0257744789123535}\n",
      "{'epoch': 2, 'batch': 151, 'loss': 6.070400238037109}\n",
      "{'epoch': 2, 'batch': 152, 'loss': 5.997724533081055}\n",
      "{'epoch': 2, 'batch': 153, 'loss': 6.129347324371338}\n",
      "{'epoch': 2, 'batch': 154, 'loss': 6.086463451385498}\n",
      "{'epoch': 2, 'batch': 155, 'loss': 6.179675579071045}\n",
      "{'epoch': 2, 'batch': 156, 'loss': 6.114367485046387}\n",
      "{'epoch': 2, 'batch': 157, 'loss': 6.057453155517578}\n",
      "{'epoch': 2, 'batch': 158, 'loss': 6.158566474914551}\n",
      "{'epoch': 2, 'batch': 159, 'loss': 6.0636796951293945}\n",
      "{'epoch': 2, 'batch': 160, 'loss': 5.996429443359375}\n",
      "{'epoch': 2, 'batch': 161, 'loss': 6.118009090423584}\n",
      "{'epoch': 2, 'batch': 162, 'loss': 6.0302815437316895}\n",
      "{'epoch': 2, 'batch': 163, 'loss': 6.195515155792236}\n",
      "{'epoch': 2, 'batch': 164, 'loss': 5.987973690032959}\n",
      "{'epoch': 2, 'batch': 165, 'loss': 6.044336795806885}\n",
      "{'epoch': 2, 'batch': 166, 'loss': 5.967967987060547}\n",
      "{'epoch': 2, 'batch': 167, 'loss': 6.01961612701416}\n",
      "{'epoch': 2, 'batch': 168, 'loss': 6.040307521820068}\n",
      "{'epoch': 2, 'batch': 169, 'loss': 5.996694564819336}\n",
      "{'epoch': 2, 'batch': 170, 'loss': 5.961611270904541}\n",
      "{'epoch': 2, 'batch': 171, 'loss': 6.013733386993408}\n",
      "{'epoch': 2, 'batch': 172, 'loss': 5.93501091003418}\n",
      "{'epoch': 2, 'batch': 173, 'loss': 5.967082977294922}\n",
      "{'epoch': 2, 'batch': 174, 'loss': 5.966679573059082}\n",
      "{'epoch': 2, 'batch': 175, 'loss': 5.961989402770996}\n",
      "{'epoch': 2, 'batch': 176, 'loss': 5.975414752960205}\n",
      "{'epoch': 2, 'batch': 177, 'loss': 6.196308135986328}\n",
      "{'epoch': 2, 'batch': 178, 'loss': 5.977810859680176}\n",
      "{'epoch': 2, 'batch': 179, 'loss': 6.072185516357422}\n",
      "{'epoch': 2, 'batch': 180, 'loss': 6.1650285720825195}\n",
      "{'epoch': 2, 'batch': 181, 'loss': 6.065123081207275}\n",
      "{'epoch': 2, 'batch': 182, 'loss': 6.115983009338379}\n",
      "{'epoch': 2, 'batch': 183, 'loss': 6.033919811248779}\n",
      "{'epoch': 2, 'batch': 184, 'loss': 6.054771423339844}\n",
      "{'epoch': 2, 'batch': 185, 'loss': 5.877320289611816}\n",
      "{'epoch': 2, 'batch': 186, 'loss': 6.225464820861816}\n",
      "{'epoch': 2, 'batch': 187, 'loss': 6.066323280334473}\n",
      "{'epoch': 2, 'batch': 188, 'loss': 6.047828197479248}\n",
      "{'epoch': 2, 'batch': 189, 'loss': 6.1804094314575195}\n",
      "{'epoch': 2, 'batch': 190, 'loss': 6.037862300872803}\n",
      "{'epoch': 2, 'batch': 191, 'loss': 6.119935035705566}\n",
      "{'epoch': 2, 'batch': 192, 'loss': 5.964906692504883}\n",
      "{'epoch': 2, 'batch': 193, 'loss': 6.147215366363525}\n",
      "{'epoch': 2, 'batch': 194, 'loss': 6.108123302459717}\n",
      "{'epoch': 2, 'batch': 195, 'loss': 6.0804362297058105}\n",
      "{'epoch': 2, 'batch': 196, 'loss': 5.961374282836914}\n",
      "{'epoch': 2, 'batch': 197, 'loss': 6.021336078643799}\n",
      "{'epoch': 2, 'batch': 198, 'loss': 6.077157497406006}\n",
      "{'epoch': 2, 'batch': 199, 'loss': 6.024665832519531}\n",
      "{'epoch': 2, 'batch': 200, 'loss': 6.056608200073242}\n",
      "{'epoch': 2, 'batch': 201, 'loss': 5.930283546447754}\n",
      "{'epoch': 2, 'batch': 202, 'loss': 5.9291768074035645}\n",
      "{'epoch': 2, 'batch': 203, 'loss': 5.990614891052246}\n",
      "{'epoch': 2, 'batch': 204, 'loss': 6.033319473266602}\n",
      "{'epoch': 2, 'batch': 205, 'loss': 6.054016590118408}\n",
      "{'epoch': 2, 'batch': 206, 'loss': 5.984788417816162}\n",
      "{'epoch': 2, 'batch': 207, 'loss': 5.969079494476318}\n",
      "{'epoch': 2, 'batch': 208, 'loss': 5.867399215698242}\n",
      "{'epoch': 2, 'batch': 209, 'loss': 5.995805263519287}\n",
      "{'epoch': 2, 'batch': 210, 'loss': 5.903194427490234}\n",
      "{'epoch': 2, 'batch': 211, 'loss': 6.085606098175049}\n",
      "{'epoch': 2, 'batch': 212, 'loss': 5.930393695831299}\n",
      "{'epoch': 2, 'batch': 213, 'loss': 6.082447052001953}\n",
      "{'epoch': 2, 'batch': 214, 'loss': 5.959857940673828}\n",
      "{'epoch': 2, 'batch': 215, 'loss': 5.991300106048584}\n",
      "{'epoch': 2, 'batch': 216, 'loss': 6.060513019561768}\n",
      "{'epoch': 2, 'batch': 217, 'loss': 5.917905330657959}\n",
      "{'epoch': 2, 'batch': 218, 'loss': 6.038339138031006}\n",
      "{'epoch': 2, 'batch': 219, 'loss': 6.0121355056762695}\n",
      "{'epoch': 2, 'batch': 220, 'loss': 6.058293342590332}\n",
      "{'epoch': 2, 'batch': 221, 'loss': 5.940217018127441}\n",
      "{'epoch': 2, 'batch': 222, 'loss': 5.965534210205078}\n",
      "{'epoch': 2, 'batch': 223, 'loss': 5.89272403717041}\n",
      "{'epoch': 2, 'batch': 224, 'loss': 5.961179733276367}\n",
      "{'epoch': 2, 'batch': 225, 'loss': 5.797855854034424}\n",
      "{'epoch': 2, 'batch': 226, 'loss': 5.911727428436279}\n",
      "{'epoch': 2, 'batch': 227, 'loss': 6.120889186859131}\n",
      "{'epoch': 2, 'batch': 228, 'loss': 5.991379261016846}\n",
      "{'epoch': 2, 'batch': 229, 'loss': 5.914900302886963}\n",
      "{'epoch': 2, 'batch': 230, 'loss': 6.038991928100586}\n",
      "{'epoch': 2, 'batch': 231, 'loss': 5.78237247467041}\n",
      "{'epoch': 2, 'batch': 232, 'loss': 5.978748798370361}\n",
      "{'epoch': 2, 'batch': 233, 'loss': 6.0786237716674805}\n",
      "{'epoch': 2, 'batch': 234, 'loss': 5.96705961227417}\n",
      "{'epoch': 2, 'batch': 235, 'loss': 5.739133358001709}\n",
      "{'epoch': 2, 'batch': 236, 'loss': 5.802383899688721}\n",
      "{'epoch': 2, 'batch': 237, 'loss': 5.815149784088135}\n",
      "{'epoch': 2, 'batch': 238, 'loss': 5.830027103424072}\n",
      "{'epoch': 2, 'batch': 239, 'loss': 5.84015417098999}\n",
      "{'epoch': 2, 'batch': 240, 'loss': 5.8930439949035645}\n",
      "{'epoch': 2, 'batch': 241, 'loss': 5.924132823944092}\n",
      "{'epoch': 2, 'batch': 242, 'loss': 5.93123722076416}\n",
      "{'epoch': 2, 'batch': 243, 'loss': 5.826895713806152}\n",
      "{'epoch': 2, 'batch': 244, 'loss': 6.086759090423584}\n",
      "{'epoch': 2, 'batch': 245, 'loss': 5.890276908874512}\n",
      "{'epoch': 2, 'batch': 246, 'loss': 5.915349960327148}\n",
      "{'epoch': 2, 'batch': 247, 'loss': 5.916370868682861}\n",
      "{'epoch': 2, 'batch': 248, 'loss': 5.938048839569092}\n",
      "{'epoch': 2, 'batch': 249, 'loss': 5.884533882141113}\n",
      "{'epoch': 2, 'batch': 250, 'loss': 5.8317790031433105}\n",
      "{'epoch': 2, 'batch': 251, 'loss': 5.768780708312988}\n",
      "{'epoch': 2, 'batch': 252, 'loss': 5.858855724334717}\n",
      "{'epoch': 2, 'batch': 253, 'loss': 5.812710285186768}\n",
      "{'epoch': 2, 'batch': 254, 'loss': 5.966721534729004}\n",
      "{'epoch': 2, 'batch': 255, 'loss': 6.052455902099609}\n",
      "{'epoch': 2, 'batch': 256, 'loss': 5.905020713806152}\n",
      "{'epoch': 2, 'batch': 257, 'loss': 5.829607963562012}\n",
      "{'epoch': 2, 'batch': 258, 'loss': 5.827106952667236}\n",
      "{'epoch': 2, 'batch': 259, 'loss': 5.924116134643555}\n",
      "{'epoch': 2, 'batch': 260, 'loss': 6.09448766708374}\n",
      "{'epoch': 2, 'batch': 261, 'loss': 5.929995059967041}\n",
      "{'epoch': 2, 'batch': 262, 'loss': 5.927787780761719}\n",
      "{'epoch': 2, 'batch': 263, 'loss': 5.9396257400512695}\n",
      "{'epoch': 2, 'batch': 264, 'loss': 5.871257305145264}\n",
      "{'epoch': 2, 'batch': 265, 'loss': 5.914971351623535}\n",
      "{'epoch': 2, 'batch': 266, 'loss': 5.848259449005127}\n",
      "{'epoch': 2, 'batch': 267, 'loss': 5.739792346954346}\n",
      "{'epoch': 2, 'batch': 268, 'loss': 5.894345760345459}\n",
      "{'epoch': 2, 'batch': 269, 'loss': 5.888542175292969}\n",
      "{'epoch': 2, 'batch': 270, 'loss': 5.865579605102539}\n",
      "{'epoch': 2, 'batch': 271, 'loss': 5.719984531402588}\n",
      "{'epoch': 2, 'batch': 272, 'loss': 5.97543478012085}\n",
      "{'epoch': 2, 'batch': 273, 'loss': 6.137554168701172}\n",
      "{'epoch': 2, 'batch': 274, 'loss': 5.7918219566345215}\n",
      "{'epoch': 2, 'batch': 275, 'loss': 5.869617462158203}\n",
      "{'epoch': 2, 'batch': 276, 'loss': 5.897702217102051}\n",
      "{'epoch': 2, 'batch': 277, 'loss': 6.001996040344238}\n",
      "{'epoch': 2, 'batch': 278, 'loss': 5.9389801025390625}\n",
      "{'epoch': 2, 'batch': 279, 'loss': 5.9073381423950195}\n",
      "{'epoch': 2, 'batch': 280, 'loss': 5.738587856292725}\n",
      "{'epoch': 2, 'batch': 281, 'loss': 5.932589054107666}\n",
      "{'epoch': 2, 'batch': 282, 'loss': 5.789943695068359}\n",
      "{'epoch': 2, 'batch': 283, 'loss': 5.855592727661133}\n",
      "{'epoch': 2, 'batch': 284, 'loss': 5.833430290222168}\n",
      "{'epoch': 2, 'batch': 285, 'loss': 5.833924770355225}\n",
      "{'epoch': 2, 'batch': 286, 'loss': 5.8132524490356445}\n",
      "{'epoch': 2, 'batch': 287, 'loss': 5.960467338562012}\n",
      "{'epoch': 2, 'batch': 288, 'loss': 5.8728861808776855}\n",
      "{'epoch': 2, 'batch': 289, 'loss': 5.823333740234375}\n",
      "{'epoch': 2, 'batch': 290, 'loss': 5.734011650085449}\n",
      "{'epoch': 2, 'batch': 291, 'loss': 5.938687324523926}\n",
      "{'epoch': 2, 'batch': 292, 'loss': 5.7679572105407715}\n",
      "{'epoch': 2, 'batch': 293, 'loss': 5.8626813888549805}\n",
      "{'epoch': 2, 'batch': 294, 'loss': 5.829010963439941}\n",
      "{'epoch': 2, 'batch': 295, 'loss': 5.897434711456299}\n",
      "{'epoch': 2, 'batch': 296, 'loss': 5.872128963470459}\n",
      "{'epoch': 2, 'batch': 297, 'loss': 5.763103485107422}\n",
      "{'epoch': 2, 'batch': 298, 'loss': 5.9842023849487305}\n",
      "{'epoch': 2, 'batch': 299, 'loss': 5.845361232757568}\n",
      "{'epoch': 2, 'batch': 300, 'loss': 5.770406246185303}\n",
      "{'epoch': 2, 'batch': 301, 'loss': 6.025393009185791}\n",
      "{'epoch': 2, 'batch': 302, 'loss': 5.932949542999268}\n",
      "{'epoch': 2, 'batch': 303, 'loss': 5.843955039978027}\n"
     ]
    }
   ],
   "source": [
    "dataset = RNN_Dataset_multiple_sources(TRAIN_TOKEN_LEN, \"mar_2023_lowercase_reviews_small_vocab.pt\", \"lowercase_garden_small_tok.pkl\", \"lowercase_music_small_tok.pkl\")\n",
    "input_size = dataset.uniq_words # Should be size of vocab?\n",
    "hidden_size = 256\n",
    "n_layers = 3\n",
    "num_epochs = 3\n",
    "\n",
    "category_model = GRU_category(input_size, hidden_size, input_size, n_layers).to(device)\n",
    "\n",
    "file_path = f\"gru_trained_cat_reviews.pt\"\n",
    "\n",
    "losses_cat = train(dataset, category_model, num_epochs, BATCH_SIZE, cat=True)\n",
    "\n",
    "torch.save(category_model.state_dict(), file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n",
      "Vocabulary sizes:\n",
      "33806\n",
      "Number of raw_tokens:  1245513\n",
      "Number of samples in a batch:  4865\n",
      "Number of batches:  304\n",
      "{'epoch': 0, 'batch': 0, 'loss': 10.433921813964844}\n",
      "{'epoch': 0, 'batch': 1, 'loss': 10.302325248718262}\n",
      "{'epoch': 0, 'batch': 2, 'loss': 10.084747314453125}\n",
      "{'epoch': 0, 'batch': 3, 'loss': 9.768202781677246}\n",
      "{'epoch': 0, 'batch': 4, 'loss': 9.317633628845215}\n",
      "{'epoch': 0, 'batch': 5, 'loss': 8.877665519714355}\n",
      "{'epoch': 0, 'batch': 6, 'loss': 8.537729263305664}\n",
      "{'epoch': 0, 'batch': 7, 'loss': 8.163792610168457}\n",
      "{'epoch': 0, 'batch': 8, 'loss': 7.851109027862549}\n",
      "{'epoch': 0, 'batch': 9, 'loss': 7.532853603363037}\n",
      "{'epoch': 0, 'batch': 10, 'loss': 7.365812301635742}\n",
      "{'epoch': 0, 'batch': 11, 'loss': 7.108844757080078}\n",
      "{'epoch': 0, 'batch': 12, 'loss': 7.009706974029541}\n",
      "{'epoch': 0, 'batch': 13, 'loss': 6.869292736053467}\n",
      "{'epoch': 0, 'batch': 14, 'loss': 6.7958221435546875}\n",
      "{'epoch': 0, 'batch': 15, 'loss': 6.790960311889648}\n",
      "{'epoch': 0, 'batch': 16, 'loss': 6.732971668243408}\n",
      "{'epoch': 0, 'batch': 17, 'loss': 6.6945481300354}\n",
      "{'epoch': 0, 'batch': 18, 'loss': 6.640256404876709}\n",
      "{'epoch': 0, 'batch': 19, 'loss': 6.691982746124268}\n",
      "{'epoch': 0, 'batch': 20, 'loss': 6.550219535827637}\n",
      "{'epoch': 0, 'batch': 21, 'loss': 6.636813640594482}\n",
      "{'epoch': 0, 'batch': 22, 'loss': 6.66100549697876}\n",
      "{'epoch': 0, 'batch': 23, 'loss': 6.510369300842285}\n",
      "{'epoch': 0, 'batch': 24, 'loss': 6.611505508422852}\n",
      "{'epoch': 0, 'batch': 25, 'loss': 6.591955661773682}\n",
      "{'epoch': 0, 'batch': 26, 'loss': 6.6603498458862305}\n",
      "{'epoch': 0, 'batch': 27, 'loss': 6.587862014770508}\n",
      "{'epoch': 0, 'batch': 28, 'loss': 6.665812969207764}\n",
      "{'epoch': 0, 'batch': 29, 'loss': 6.643074989318848}\n",
      "{'epoch': 0, 'batch': 30, 'loss': 6.600685119628906}\n",
      "{'epoch': 0, 'batch': 31, 'loss': 6.6827921867370605}\n",
      "{'epoch': 0, 'batch': 32, 'loss': 6.7548933029174805}\n",
      "{'epoch': 0, 'batch': 33, 'loss': 6.628414154052734}\n",
      "{'epoch': 0, 'batch': 34, 'loss': 6.689908504486084}\n",
      "{'epoch': 0, 'batch': 35, 'loss': 6.5824875831604}\n",
      "{'epoch': 0, 'batch': 36, 'loss': 6.729496479034424}\n",
      "{'epoch': 0, 'batch': 37, 'loss': 6.5496721267700195}\n",
      "{'epoch': 0, 'batch': 38, 'loss': 6.623817443847656}\n",
      "{'epoch': 0, 'batch': 39, 'loss': 6.658230781555176}\n",
      "{'epoch': 0, 'batch': 40, 'loss': 6.519392490386963}\n",
      "{'epoch': 0, 'batch': 41, 'loss': 6.521453380584717}\n",
      "{'epoch': 0, 'batch': 42, 'loss': 6.580117225646973}\n",
      "{'epoch': 0, 'batch': 43, 'loss': 6.473362445831299}\n",
      "{'epoch': 0, 'batch': 44, 'loss': 6.493626594543457}\n",
      "{'epoch': 0, 'batch': 45, 'loss': 6.572348594665527}\n",
      "{'epoch': 0, 'batch': 46, 'loss': 6.775757312774658}\n",
      "{'epoch': 0, 'batch': 47, 'loss': 6.562307357788086}\n",
      "{'epoch': 0, 'batch': 48, 'loss': 6.542401313781738}\n",
      "{'epoch': 0, 'batch': 49, 'loss': 6.451147079467773}\n",
      "{'epoch': 0, 'batch': 50, 'loss': 6.529775142669678}\n",
      "{'epoch': 0, 'batch': 51, 'loss': 6.607020378112793}\n",
      "{'epoch': 0, 'batch': 52, 'loss': 6.541172504425049}\n",
      "{'epoch': 0, 'batch': 53, 'loss': 6.45639705657959}\n",
      "{'epoch': 0, 'batch': 54, 'loss': 6.604150295257568}\n",
      "{'epoch': 0, 'batch': 55, 'loss': 6.6251444816589355}\n",
      "{'epoch': 0, 'batch': 56, 'loss': 6.579620838165283}\n",
      "{'epoch': 0, 'batch': 57, 'loss': 6.529256343841553}\n",
      "{'epoch': 0, 'batch': 58, 'loss': 6.5283942222595215}\n",
      "{'epoch': 0, 'batch': 59, 'loss': 6.563373565673828}\n",
      "{'epoch': 0, 'batch': 60, 'loss': 6.684045791625977}\n",
      "{'epoch': 0, 'batch': 61, 'loss': 6.658498287200928}\n",
      "{'epoch': 0, 'batch': 62, 'loss': 6.4674530029296875}\n",
      "{'epoch': 0, 'batch': 63, 'loss': 6.493508338928223}\n",
      "{'epoch': 0, 'batch': 64, 'loss': 6.448121070861816}\n",
      "{'epoch': 0, 'batch': 65, 'loss': 6.474431991577148}\n",
      "{'epoch': 0, 'batch': 66, 'loss': 6.552581310272217}\n",
      "{'epoch': 0, 'batch': 67, 'loss': 6.602964878082275}\n",
      "{'epoch': 0, 'batch': 68, 'loss': 6.583895206451416}\n",
      "{'epoch': 0, 'batch': 69, 'loss': 6.555297374725342}\n",
      "{'epoch': 0, 'batch': 70, 'loss': 6.781924247741699}\n",
      "{'epoch': 0, 'batch': 71, 'loss': 6.652645111083984}\n",
      "{'epoch': 0, 'batch': 72, 'loss': 6.482722759246826}\n",
      "{'epoch': 0, 'batch': 73, 'loss': 6.553362846374512}\n",
      "{'epoch': 0, 'batch': 74, 'loss': 6.720383167266846}\n",
      "{'epoch': 0, 'batch': 75, 'loss': 6.600434303283691}\n",
      "{'epoch': 0, 'batch': 76, 'loss': 6.51906681060791}\n",
      "{'epoch': 0, 'batch': 77, 'loss': 6.6153717041015625}\n",
      "{'epoch': 0, 'batch': 78, 'loss': 6.495625019073486}\n",
      "{'epoch': 0, 'batch': 79, 'loss': 6.665154933929443}\n",
      "{'epoch': 0, 'batch': 80, 'loss': 6.411018371582031}\n",
      "{'epoch': 0, 'batch': 81, 'loss': 6.5660481452941895}\n",
      "{'epoch': 0, 'batch': 82, 'loss': 6.6219258308410645}\n",
      "{'epoch': 0, 'batch': 83, 'loss': 6.467496871948242}\n",
      "{'epoch': 0, 'batch': 84, 'loss': 6.480533123016357}\n",
      "{'epoch': 0, 'batch': 85, 'loss': 6.523215293884277}\n",
      "{'epoch': 0, 'batch': 86, 'loss': 6.497744083404541}\n",
      "{'epoch': 0, 'batch': 87, 'loss': 6.579458713531494}\n",
      "{'epoch': 0, 'batch': 88, 'loss': 6.580222129821777}\n",
      "{'epoch': 0, 'batch': 89, 'loss': 6.543900012969971}\n",
      "{'epoch': 0, 'batch': 90, 'loss': 6.578004837036133}\n",
      "{'epoch': 0, 'batch': 91, 'loss': 6.498794078826904}\n",
      "{'epoch': 0, 'batch': 92, 'loss': 6.475640296936035}\n",
      "{'epoch': 0, 'batch': 93, 'loss': 6.52549409866333}\n",
      "{'epoch': 0, 'batch': 94, 'loss': 6.420223236083984}\n",
      "{'epoch': 0, 'batch': 95, 'loss': 6.517611980438232}\n",
      "{'epoch': 0, 'batch': 96, 'loss': 6.536877155303955}\n",
      "{'epoch': 0, 'batch': 97, 'loss': 6.5749711990356445}\n",
      "{'epoch': 0, 'batch': 98, 'loss': 6.537752628326416}\n",
      "{'epoch': 0, 'batch': 99, 'loss': 6.483349323272705}\n",
      "{'epoch': 0, 'batch': 100, 'loss': 6.404690265655518}\n",
      "{'epoch': 0, 'batch': 101, 'loss': 6.537154674530029}\n",
      "{'epoch': 0, 'batch': 102, 'loss': 6.509720325469971}\n",
      "{'epoch': 0, 'batch': 103, 'loss': 6.564968585968018}\n",
      "{'epoch': 0, 'batch': 104, 'loss': 6.471089839935303}\n",
      "{'epoch': 0, 'batch': 105, 'loss': 6.568980693817139}\n",
      "{'epoch': 0, 'batch': 106, 'loss': 6.5163421630859375}\n",
      "{'epoch': 0, 'batch': 107, 'loss': 6.485939025878906}\n",
      "{'epoch': 0, 'batch': 108, 'loss': 6.4714460372924805}\n",
      "{'epoch': 0, 'batch': 109, 'loss': 6.474377632141113}\n",
      "{'epoch': 0, 'batch': 110, 'loss': 6.604557514190674}\n",
      "{'epoch': 0, 'batch': 111, 'loss': 6.596794128417969}\n",
      "{'epoch': 0, 'batch': 112, 'loss': 6.619823455810547}\n",
      "{'epoch': 0, 'batch': 113, 'loss': 6.554037570953369}\n",
      "{'epoch': 0, 'batch': 114, 'loss': 6.526161193847656}\n",
      "{'epoch': 0, 'batch': 115, 'loss': 6.462181568145752}\n",
      "{'epoch': 0, 'batch': 116, 'loss': 6.499510765075684}\n",
      "{'epoch': 0, 'batch': 117, 'loss': 6.545803070068359}\n",
      "{'epoch': 0, 'batch': 118, 'loss': 6.482283115386963}\n",
      "{'epoch': 0, 'batch': 119, 'loss': 6.5257954597473145}\n",
      "{'epoch': 0, 'batch': 120, 'loss': 6.541177749633789}\n",
      "{'epoch': 0, 'batch': 121, 'loss': 6.673224449157715}\n",
      "{'epoch': 0, 'batch': 122, 'loss': 6.669667720794678}\n",
      "{'epoch': 0, 'batch': 123, 'loss': 6.524227142333984}\n",
      "{'epoch': 0, 'batch': 124, 'loss': 6.5950846672058105}\n",
      "{'epoch': 0, 'batch': 125, 'loss': 6.612286567687988}\n",
      "{'epoch': 0, 'batch': 126, 'loss': 6.456182479858398}\n",
      "{'epoch': 0, 'batch': 127, 'loss': 6.497358798980713}\n",
      "{'epoch': 0, 'batch': 128, 'loss': 6.589794635772705}\n",
      "{'epoch': 0, 'batch': 129, 'loss': 6.394492149353027}\n",
      "{'epoch': 0, 'batch': 130, 'loss': 6.600323677062988}\n",
      "{'epoch': 0, 'batch': 131, 'loss': 6.475651741027832}\n",
      "{'epoch': 0, 'batch': 132, 'loss': 6.683624267578125}\n",
      "{'epoch': 0, 'batch': 133, 'loss': 6.533789157867432}\n",
      "{'epoch': 0, 'batch': 134, 'loss': 6.472029209136963}\n",
      "{'epoch': 0, 'batch': 135, 'loss': 6.514500617980957}\n",
      "{'epoch': 0, 'batch': 136, 'loss': 6.5377397537231445}\n",
      "{'epoch': 0, 'batch': 137, 'loss': 6.388910293579102}\n",
      "{'epoch': 0, 'batch': 138, 'loss': 6.56931734085083}\n",
      "{'epoch': 0, 'batch': 139, 'loss': 6.509698867797852}\n",
      "{'epoch': 0, 'batch': 140, 'loss': 6.457836627960205}\n",
      "{'epoch': 0, 'batch': 141, 'loss': 6.472371578216553}\n",
      "{'epoch': 0, 'batch': 142, 'loss': 6.516507625579834}\n",
      "{'epoch': 0, 'batch': 143, 'loss': 6.567413806915283}\n",
      "{'epoch': 0, 'batch': 144, 'loss': 6.591559886932373}\n",
      "{'epoch': 0, 'batch': 145, 'loss': 6.550461769104004}\n",
      "{'epoch': 0, 'batch': 146, 'loss': 6.588766098022461}\n",
      "{'epoch': 0, 'batch': 147, 'loss': 6.504489421844482}\n",
      "{'epoch': 0, 'batch': 148, 'loss': 6.492555141448975}\n",
      "{'epoch': 0, 'batch': 149, 'loss': 6.5873517990112305}\n",
      "{'epoch': 0, 'batch': 150, 'loss': 6.460636138916016}\n",
      "{'epoch': 0, 'batch': 151, 'loss': 6.600419044494629}\n",
      "{'epoch': 0, 'batch': 152, 'loss': 6.631369590759277}\n",
      "{'epoch': 0, 'batch': 153, 'loss': 6.550402641296387}\n",
      "{'epoch': 0, 'batch': 154, 'loss': 6.4229936599731445}\n",
      "{'epoch': 0, 'batch': 155, 'loss': 6.63594388961792}\n",
      "{'epoch': 0, 'batch': 156, 'loss': 6.526573181152344}\n",
      "{'epoch': 0, 'batch': 157, 'loss': 6.550222396850586}\n",
      "{'epoch': 0, 'batch': 158, 'loss': 6.482635974884033}\n",
      "{'epoch': 0, 'batch': 159, 'loss': 6.614736557006836}\n",
      "{'epoch': 0, 'batch': 160, 'loss': 6.484233856201172}\n",
      "{'epoch': 0, 'batch': 161, 'loss': 6.492876052856445}\n",
      "{'epoch': 0, 'batch': 162, 'loss': 6.447188377380371}\n",
      "{'epoch': 0, 'batch': 163, 'loss': 6.528026103973389}\n",
      "{'epoch': 0, 'batch': 164, 'loss': 6.5234479904174805}\n",
      "{'epoch': 0, 'batch': 165, 'loss': 6.617119312286377}\n",
      "{'epoch': 0, 'batch': 166, 'loss': 6.613913059234619}\n",
      "{'epoch': 0, 'batch': 167, 'loss': 6.611719608306885}\n",
      "{'epoch': 0, 'batch': 168, 'loss': 6.468042373657227}\n",
      "{'epoch': 0, 'batch': 169, 'loss': 6.496705055236816}\n",
      "{'epoch': 0, 'batch': 170, 'loss': 6.505935192108154}\n",
      "{'epoch': 0, 'batch': 171, 'loss': 6.549362659454346}\n",
      "{'epoch': 0, 'batch': 172, 'loss': 6.487154006958008}\n",
      "{'epoch': 0, 'batch': 173, 'loss': 6.548355579376221}\n",
      "{'epoch': 0, 'batch': 174, 'loss': 6.407315254211426}\n",
      "{'epoch': 0, 'batch': 175, 'loss': 6.55393123626709}\n",
      "{'epoch': 0, 'batch': 176, 'loss': 6.5393147468566895}\n",
      "{'epoch': 0, 'batch': 177, 'loss': 6.467887878417969}\n",
      "{'epoch': 0, 'batch': 178, 'loss': 6.492086887359619}\n",
      "{'epoch': 0, 'batch': 179, 'loss': 6.61126708984375}\n",
      "{'epoch': 0, 'batch': 180, 'loss': 6.538965225219727}\n",
      "{'epoch': 0, 'batch': 181, 'loss': 6.635787010192871}\n",
      "{'epoch': 0, 'batch': 182, 'loss': 6.6152496337890625}\n",
      "{'epoch': 0, 'batch': 183, 'loss': 6.454275131225586}\n",
      "{'epoch': 0, 'batch': 184, 'loss': 6.679187774658203}\n",
      "{'epoch': 0, 'batch': 185, 'loss': 6.484113693237305}\n",
      "{'epoch': 0, 'batch': 186, 'loss': 6.528348445892334}\n",
      "{'epoch': 0, 'batch': 187, 'loss': 6.498546600341797}\n",
      "{'epoch': 0, 'batch': 188, 'loss': 6.550070762634277}\n",
      "{'epoch': 0, 'batch': 189, 'loss': 6.386425018310547}\n",
      "{'epoch': 0, 'batch': 190, 'loss': 6.606714248657227}\n",
      "{'epoch': 0, 'batch': 191, 'loss': 6.437602996826172}\n",
      "{'epoch': 0, 'batch': 192, 'loss': 6.487729072570801}\n",
      "{'epoch': 0, 'batch': 193, 'loss': 6.546630382537842}\n",
      "{'epoch': 0, 'batch': 194, 'loss': 6.552566051483154}\n",
      "{'epoch': 0, 'batch': 195, 'loss': 6.474360942840576}\n",
      "{'epoch': 0, 'batch': 196, 'loss': 6.526656627655029}\n",
      "{'epoch': 0, 'batch': 197, 'loss': 6.625646114349365}\n",
      "{'epoch': 0, 'batch': 198, 'loss': 6.541110038757324}\n",
      "{'epoch': 0, 'batch': 199, 'loss': 6.652624607086182}\n",
      "{'epoch': 0, 'batch': 200, 'loss': 6.508728981018066}\n",
      "{'epoch': 0, 'batch': 201, 'loss': 6.457290172576904}\n",
      "{'epoch': 0, 'batch': 202, 'loss': 6.586842060089111}\n",
      "{'epoch': 0, 'batch': 203, 'loss': 6.479625225067139}\n",
      "{'epoch': 0, 'batch': 204, 'loss': 6.487407207489014}\n",
      "{'epoch': 0, 'batch': 205, 'loss': 6.554642200469971}\n",
      "{'epoch': 0, 'batch': 206, 'loss': 6.502230167388916}\n",
      "{'epoch': 0, 'batch': 207, 'loss': 6.509372234344482}\n",
      "{'epoch': 0, 'batch': 208, 'loss': 6.581996917724609}\n",
      "{'epoch': 0, 'batch': 209, 'loss': 6.635323524475098}\n",
      "{'epoch': 0, 'batch': 210, 'loss': 6.487308502197266}\n",
      "{'epoch': 0, 'batch': 211, 'loss': 6.559293746948242}\n",
      "{'epoch': 0, 'batch': 212, 'loss': 6.510680198669434}\n",
      "{'epoch': 0, 'batch': 213, 'loss': 6.539577960968018}\n",
      "{'epoch': 0, 'batch': 214, 'loss': 6.526549816131592}\n",
      "{'epoch': 0, 'batch': 215, 'loss': 6.569506645202637}\n",
      "{'epoch': 0, 'batch': 216, 'loss': 6.53960657119751}\n",
      "{'epoch': 0, 'batch': 217, 'loss': 6.5190229415893555}\n",
      "{'epoch': 0, 'batch': 218, 'loss': 6.5074028968811035}\n",
      "{'epoch': 0, 'batch': 219, 'loss': 6.498739719390869}\n",
      "{'epoch': 0, 'batch': 220, 'loss': 6.616364479064941}\n",
      "{'epoch': 0, 'batch': 221, 'loss': 6.450375080108643}\n",
      "{'epoch': 0, 'batch': 222, 'loss': 6.686768531799316}\n",
      "{'epoch': 0, 'batch': 223, 'loss': 6.538467884063721}\n",
      "{'epoch': 0, 'batch': 224, 'loss': 6.618628978729248}\n",
      "{'epoch': 0, 'batch': 225, 'loss': 6.6824727058410645}\n",
      "{'epoch': 0, 'batch': 226, 'loss': 6.576959133148193}\n",
      "{'epoch': 0, 'batch': 227, 'loss': 6.551729202270508}\n",
      "{'epoch': 0, 'batch': 228, 'loss': 6.6761474609375}\n",
      "{'epoch': 0, 'batch': 229, 'loss': 6.635087490081787}\n",
      "{'epoch': 0, 'batch': 230, 'loss': 6.485385894775391}\n",
      "{'epoch': 0, 'batch': 231, 'loss': 6.479648590087891}\n",
      "{'epoch': 0, 'batch': 232, 'loss': 6.582302570343018}\n",
      "{'epoch': 0, 'batch': 233, 'loss': 6.532003879547119}\n",
      "{'epoch': 0, 'batch': 234, 'loss': 6.566425800323486}\n",
      "{'epoch': 0, 'batch': 235, 'loss': 6.5867719650268555}\n",
      "{'epoch': 0, 'batch': 236, 'loss': 6.539054870605469}\n",
      "{'epoch': 0, 'batch': 237, 'loss': 6.445736885070801}\n",
      "{'epoch': 0, 'batch': 238, 'loss': 6.647256851196289}\n",
      "{'epoch': 0, 'batch': 239, 'loss': 6.627455711364746}\n",
      "{'epoch': 0, 'batch': 240, 'loss': 6.62492036819458}\n",
      "{'epoch': 0, 'batch': 241, 'loss': 6.790878772735596}\n",
      "{'epoch': 0, 'batch': 242, 'loss': 6.544004440307617}\n",
      "{'epoch': 0, 'batch': 243, 'loss': 6.592060565948486}\n",
      "{'epoch': 0, 'batch': 244, 'loss': 6.617184638977051}\n",
      "{'epoch': 0, 'batch': 245, 'loss': 6.767789840698242}\n",
      "{'epoch': 0, 'batch': 246, 'loss': 6.550561428070068}\n",
      "{'epoch': 0, 'batch': 247, 'loss': 6.551861763000488}\n",
      "{'epoch': 0, 'batch': 248, 'loss': 6.583794116973877}\n",
      "{'epoch': 0, 'batch': 249, 'loss': 6.469117164611816}\n",
      "{'epoch': 0, 'batch': 250, 'loss': 6.46718692779541}\n",
      "{'epoch': 0, 'batch': 251, 'loss': 6.556389331817627}\n",
      "{'epoch': 0, 'batch': 252, 'loss': 6.584063529968262}\n",
      "{'epoch': 0, 'batch': 253, 'loss': 6.512130260467529}\n",
      "{'epoch': 0, 'batch': 254, 'loss': 6.625443458557129}\n",
      "{'epoch': 0, 'batch': 255, 'loss': 6.506158828735352}\n",
      "{'epoch': 0, 'batch': 256, 'loss': 6.4075164794921875}\n",
      "{'epoch': 0, 'batch': 257, 'loss': 6.591909408569336}\n",
      "{'epoch': 0, 'batch': 258, 'loss': 6.474883556365967}\n",
      "{'epoch': 0, 'batch': 259, 'loss': 6.559987545013428}\n",
      "{'epoch': 0, 'batch': 260, 'loss': 6.550602436065674}\n",
      "{'epoch': 0, 'batch': 261, 'loss': 6.593757152557373}\n",
      "{'epoch': 0, 'batch': 262, 'loss': 6.615434169769287}\n",
      "{'epoch': 0, 'batch': 263, 'loss': 6.564109802246094}\n",
      "{'epoch': 0, 'batch': 264, 'loss': 6.562108516693115}\n",
      "{'epoch': 0, 'batch': 265, 'loss': 6.441674709320068}\n",
      "{'epoch': 0, 'batch': 266, 'loss': 6.560518741607666}\n",
      "{'epoch': 0, 'batch': 267, 'loss': 6.6137614250183105}\n",
      "{'epoch': 0, 'batch': 268, 'loss': 6.519733428955078}\n",
      "{'epoch': 0, 'batch': 269, 'loss': 6.575521469116211}\n",
      "{'epoch': 0, 'batch': 270, 'loss': 6.446353912353516}\n",
      "{'epoch': 0, 'batch': 271, 'loss': 6.568586349487305}\n",
      "{'epoch': 0, 'batch': 272, 'loss': 6.471724987030029}\n",
      "{'epoch': 0, 'batch': 273, 'loss': 6.532159328460693}\n",
      "{'epoch': 0, 'batch': 274, 'loss': 6.624514579772949}\n",
      "{'epoch': 0, 'batch': 275, 'loss': 6.467263221740723}\n",
      "{'epoch': 0, 'batch': 276, 'loss': 6.56908655166626}\n",
      "{'epoch': 0, 'batch': 277, 'loss': 6.5446343421936035}\n",
      "{'epoch': 0, 'batch': 278, 'loss': 6.439921855926514}\n",
      "{'epoch': 0, 'batch': 279, 'loss': 6.627878189086914}\n",
      "{'epoch': 0, 'batch': 280, 'loss': 6.48353910446167}\n",
      "{'epoch': 0, 'batch': 281, 'loss': 6.519380569458008}\n",
      "{'epoch': 0, 'batch': 282, 'loss': 6.537917137145996}\n",
      "{'epoch': 0, 'batch': 283, 'loss': 6.490731239318848}\n",
      "{'epoch': 0, 'batch': 284, 'loss': 6.4980573654174805}\n",
      "{'epoch': 0, 'batch': 285, 'loss': 6.5403361320495605}\n",
      "{'epoch': 0, 'batch': 286, 'loss': 6.547321319580078}\n",
      "{'epoch': 0, 'batch': 287, 'loss': 6.560603618621826}\n",
      "{'epoch': 0, 'batch': 288, 'loss': 6.511223793029785}\n",
      "{'epoch': 0, 'batch': 289, 'loss': 6.631935119628906}\n",
      "{'epoch': 0, 'batch': 290, 'loss': 6.4410505294799805}\n",
      "{'epoch': 0, 'batch': 291, 'loss': 6.620093822479248}\n",
      "{'epoch': 0, 'batch': 292, 'loss': 6.462891578674316}\n",
      "{'epoch': 0, 'batch': 293, 'loss': 6.55327033996582}\n",
      "{'epoch': 0, 'batch': 294, 'loss': 6.489008903503418}\n",
      "{'epoch': 0, 'batch': 295, 'loss': 6.528650283813477}\n",
      "{'epoch': 0, 'batch': 296, 'loss': 6.485135555267334}\n",
      "{'epoch': 0, 'batch': 297, 'loss': 6.508052349090576}\n",
      "{'epoch': 0, 'batch': 298, 'loss': 6.467151641845703}\n",
      "{'epoch': 0, 'batch': 299, 'loss': 6.486740589141846}\n",
      "{'epoch': 0, 'batch': 300, 'loss': 6.542398452758789}\n",
      "{'epoch': 0, 'batch': 301, 'loss': 6.593716144561768}\n",
      "{'epoch': 0, 'batch': 302, 'loss': 6.42841911315918}\n",
      "{'epoch': 0, 'batch': 303, 'loss': 6.707507133483887}\n",
      "{'epoch': 1, 'batch': 0, 'loss': 6.633199214935303}\n",
      "{'epoch': 1, 'batch': 1, 'loss': 6.465428352355957}\n",
      "{'epoch': 1, 'batch': 2, 'loss': 6.515327453613281}\n",
      "{'epoch': 1, 'batch': 3, 'loss': 6.72869873046875}\n",
      "{'epoch': 1, 'batch': 4, 'loss': 6.5644426345825195}\n",
      "{'epoch': 1, 'batch': 5, 'loss': 6.559505462646484}\n",
      "{'epoch': 1, 'batch': 6, 'loss': 6.511484622955322}\n",
      "{'epoch': 1, 'batch': 7, 'loss': 6.485962867736816}\n",
      "{'epoch': 1, 'batch': 8, 'loss': 6.533343315124512}\n",
      "{'epoch': 1, 'batch': 9, 'loss': 6.479410648345947}\n",
      "{'epoch': 1, 'batch': 10, 'loss': 6.711922645568848}\n",
      "{'epoch': 1, 'batch': 11, 'loss': 6.492457866668701}\n",
      "{'epoch': 1, 'batch': 12, 'loss': 6.640836715698242}\n",
      "{'epoch': 1, 'batch': 13, 'loss': 6.5623955726623535}\n",
      "{'epoch': 1, 'batch': 14, 'loss': 6.413875579833984}\n",
      "{'epoch': 1, 'batch': 15, 'loss': 6.602459907531738}\n",
      "{'epoch': 1, 'batch': 16, 'loss': 6.4691057205200195}\n",
      "{'epoch': 1, 'batch': 17, 'loss': 6.629406929016113}\n",
      "{'epoch': 1, 'batch': 18, 'loss': 6.465396404266357}\n",
      "{'epoch': 1, 'batch': 19, 'loss': 6.5304975509643555}\n",
      "{'epoch': 1, 'batch': 20, 'loss': 6.442719459533691}\n",
      "{'epoch': 1, 'batch': 21, 'loss': 6.564302921295166}\n",
      "{'epoch': 1, 'batch': 22, 'loss': 6.715983867645264}\n",
      "{'epoch': 1, 'batch': 23, 'loss': 6.449886798858643}\n",
      "{'epoch': 1, 'batch': 24, 'loss': 6.417723655700684}\n",
      "{'epoch': 1, 'batch': 25, 'loss': 6.406369209289551}\n",
      "{'epoch': 1, 'batch': 26, 'loss': 6.605714321136475}\n",
      "{'epoch': 1, 'batch': 27, 'loss': 6.5439348220825195}\n",
      "{'epoch': 1, 'batch': 28, 'loss': 6.514374256134033}\n",
      "{'epoch': 1, 'batch': 29, 'loss': 6.474643230438232}\n",
      "{'epoch': 1, 'batch': 30, 'loss': 6.550967693328857}\n",
      "{'epoch': 1, 'batch': 31, 'loss': 6.471193313598633}\n",
      "{'epoch': 1, 'batch': 32, 'loss': 6.58383321762085}\n",
      "{'epoch': 1, 'batch': 33, 'loss': 6.607052326202393}\n",
      "{'epoch': 1, 'batch': 34, 'loss': 6.358388900756836}\n",
      "{'epoch': 1, 'batch': 35, 'loss': 6.668694496154785}\n",
      "{'epoch': 1, 'batch': 36, 'loss': 6.565065383911133}\n",
      "{'epoch': 1, 'batch': 37, 'loss': 6.721596717834473}\n",
      "{'epoch': 1, 'batch': 38, 'loss': 6.512330055236816}\n",
      "{'epoch': 1, 'batch': 39, 'loss': 6.387999534606934}\n",
      "{'epoch': 1, 'batch': 40, 'loss': 6.495739936828613}\n",
      "{'epoch': 1, 'batch': 41, 'loss': 6.440306186676025}\n",
      "{'epoch': 1, 'batch': 42, 'loss': 6.56478214263916}\n",
      "{'epoch': 1, 'batch': 43, 'loss': 6.611270904541016}\n",
      "{'epoch': 1, 'batch': 44, 'loss': 6.62431526184082}\n",
      "{'epoch': 1, 'batch': 45, 'loss': 6.612430572509766}\n",
      "{'epoch': 1, 'batch': 46, 'loss': 6.475130558013916}\n",
      "{'epoch': 1, 'batch': 47, 'loss': 6.570284366607666}\n",
      "{'epoch': 1, 'batch': 48, 'loss': 6.561652660369873}\n",
      "{'epoch': 1, 'batch': 49, 'loss': 6.5712409019470215}\n",
      "{'epoch': 1, 'batch': 50, 'loss': 6.501423358917236}\n",
      "{'epoch': 1, 'batch': 51, 'loss': 6.549431324005127}\n",
      "{'epoch': 1, 'batch': 52, 'loss': 6.54835319519043}\n",
      "{'epoch': 1, 'batch': 53, 'loss': 6.645524024963379}\n",
      "{'epoch': 1, 'batch': 54, 'loss': 6.391697883605957}\n",
      "{'epoch': 1, 'batch': 55, 'loss': 6.544187068939209}\n",
      "{'epoch': 1, 'batch': 56, 'loss': 6.5349602699279785}\n",
      "{'epoch': 1, 'batch': 57, 'loss': 6.6906914710998535}\n",
      "{'epoch': 1, 'batch': 58, 'loss': 6.516435623168945}\n",
      "{'epoch': 1, 'batch': 59, 'loss': 6.4878034591674805}\n",
      "{'epoch': 1, 'batch': 60, 'loss': 6.524742126464844}\n",
      "{'epoch': 1, 'batch': 61, 'loss': 6.3718581199646}\n",
      "{'epoch': 1, 'batch': 62, 'loss': 6.495822429656982}\n",
      "{'epoch': 1, 'batch': 63, 'loss': 6.4593505859375}\n",
      "{'epoch': 1, 'batch': 64, 'loss': 6.430371284484863}\n",
      "{'epoch': 1, 'batch': 65, 'loss': 6.54900598526001}\n",
      "{'epoch': 1, 'batch': 66, 'loss': 6.4468841552734375}\n",
      "{'epoch': 1, 'batch': 67, 'loss': 6.503709316253662}\n",
      "{'epoch': 1, 'batch': 68, 'loss': 6.43184232711792}\n",
      "{'epoch': 1, 'batch': 69, 'loss': 6.538552761077881}\n",
      "{'epoch': 1, 'batch': 70, 'loss': 6.556633949279785}\n",
      "{'epoch': 1, 'batch': 71, 'loss': 6.458842754364014}\n",
      "{'epoch': 1, 'batch': 72, 'loss': 6.616079807281494}\n",
      "{'epoch': 1, 'batch': 73, 'loss': 6.510618209838867}\n",
      "{'epoch': 1, 'batch': 74, 'loss': 6.511186122894287}\n",
      "{'epoch': 1, 'batch': 75, 'loss': 6.542497158050537}\n",
      "{'epoch': 1, 'batch': 76, 'loss': 6.386017322540283}\n",
      "{'epoch': 1, 'batch': 77, 'loss': 6.491762161254883}\n",
      "{'epoch': 1, 'batch': 78, 'loss': 6.61107873916626}\n",
      "{'epoch': 1, 'batch': 79, 'loss': 6.626399040222168}\n",
      "{'epoch': 1, 'batch': 80, 'loss': 6.495218276977539}\n",
      "{'epoch': 1, 'batch': 81, 'loss': 6.5368123054504395}\n",
      "{'epoch': 1, 'batch': 82, 'loss': 6.380482196807861}\n",
      "{'epoch': 1, 'batch': 83, 'loss': 6.500751972198486}\n",
      "{'epoch': 1, 'batch': 84, 'loss': 6.528750896453857}\n",
      "{'epoch': 1, 'batch': 85, 'loss': 6.427933692932129}\n",
      "{'epoch': 1, 'batch': 86, 'loss': 6.58840799331665}\n",
      "{'epoch': 1, 'batch': 87, 'loss': 6.587036609649658}\n",
      "{'epoch': 1, 'batch': 88, 'loss': 6.625094890594482}\n",
      "{'epoch': 1, 'batch': 89, 'loss': 6.371106147766113}\n",
      "{'epoch': 1, 'batch': 90, 'loss': 6.50811243057251}\n",
      "{'epoch': 1, 'batch': 91, 'loss': 6.524845123291016}\n",
      "{'epoch': 1, 'batch': 92, 'loss': 6.421735763549805}\n",
      "{'epoch': 1, 'batch': 93, 'loss': 6.633401393890381}\n",
      "{'epoch': 1, 'batch': 94, 'loss': 6.569581031799316}\n",
      "{'epoch': 1, 'batch': 95, 'loss': 6.565086841583252}\n",
      "{'epoch': 1, 'batch': 96, 'loss': 6.436150550842285}\n",
      "{'epoch': 1, 'batch': 97, 'loss': 6.421721935272217}\n",
      "{'epoch': 1, 'batch': 98, 'loss': 6.669456958770752}\n",
      "{'epoch': 1, 'batch': 99, 'loss': 6.575822830200195}\n",
      "{'epoch': 1, 'batch': 100, 'loss': 6.576616287231445}\n",
      "{'epoch': 1, 'batch': 101, 'loss': 6.5380706787109375}\n",
      "{'epoch': 1, 'batch': 102, 'loss': 6.540830612182617}\n",
      "{'epoch': 1, 'batch': 103, 'loss': 6.430315971374512}\n",
      "{'epoch': 1, 'batch': 104, 'loss': 6.555421352386475}\n",
      "{'epoch': 1, 'batch': 105, 'loss': 6.520572185516357}\n",
      "{'epoch': 1, 'batch': 106, 'loss': 6.585410118103027}\n",
      "{'epoch': 1, 'batch': 107, 'loss': 6.650489330291748}\n",
      "{'epoch': 1, 'batch': 108, 'loss': 6.589694499969482}\n",
      "{'epoch': 1, 'batch': 109, 'loss': 6.508202075958252}\n",
      "{'epoch': 1, 'batch': 110, 'loss': 6.377100944519043}\n",
      "{'epoch': 1, 'batch': 111, 'loss': 6.481494426727295}\n",
      "{'epoch': 1, 'batch': 112, 'loss': 6.692192077636719}\n",
      "{'epoch': 1, 'batch': 113, 'loss': 6.4965105056762695}\n",
      "{'epoch': 1, 'batch': 114, 'loss': 6.539549350738525}\n",
      "{'epoch': 1, 'batch': 115, 'loss': 6.5155534744262695}\n",
      "{'epoch': 1, 'batch': 116, 'loss': 6.489034175872803}\n",
      "{'epoch': 1, 'batch': 117, 'loss': 6.478560447692871}\n",
      "{'epoch': 1, 'batch': 118, 'loss': 6.559793472290039}\n",
      "{'epoch': 1, 'batch': 119, 'loss': 6.577194690704346}\n",
      "{'epoch': 1, 'batch': 120, 'loss': 6.54319429397583}\n",
      "{'epoch': 1, 'batch': 121, 'loss': 6.476495742797852}\n",
      "{'epoch': 1, 'batch': 122, 'loss': 6.482715129852295}\n",
      "{'epoch': 1, 'batch': 123, 'loss': 6.670650482177734}\n",
      "{'epoch': 1, 'batch': 124, 'loss': 6.457519054412842}\n",
      "{'epoch': 1, 'batch': 125, 'loss': 6.405538082122803}\n",
      "{'epoch': 1, 'batch': 126, 'loss': 6.478016376495361}\n",
      "{'epoch': 1, 'batch': 127, 'loss': 6.389202117919922}\n",
      "{'epoch': 1, 'batch': 128, 'loss': 6.5686140060424805}\n",
      "{'epoch': 1, 'batch': 129, 'loss': 6.49078893661499}\n",
      "{'epoch': 1, 'batch': 130, 'loss': 6.504538536071777}\n",
      "{'epoch': 1, 'batch': 131, 'loss': 6.48818302154541}\n",
      "{'epoch': 1, 'batch': 132, 'loss': 6.430241107940674}\n",
      "{'epoch': 1, 'batch': 133, 'loss': 6.527258396148682}\n",
      "{'epoch': 1, 'batch': 134, 'loss': 6.477611541748047}\n",
      "{'epoch': 1, 'batch': 135, 'loss': 6.463222503662109}\n",
      "{'epoch': 1, 'batch': 136, 'loss': 6.48063325881958}\n",
      "{'epoch': 1, 'batch': 137, 'loss': 6.473330497741699}\n",
      "{'epoch': 1, 'batch': 138, 'loss': 6.4684319496154785}\n",
      "{'epoch': 1, 'batch': 139, 'loss': 6.524026393890381}\n",
      "{'epoch': 1, 'batch': 140, 'loss': 6.581151962280273}\n",
      "{'epoch': 1, 'batch': 141, 'loss': 6.498483657836914}\n",
      "{'epoch': 1, 'batch': 142, 'loss': 6.446637153625488}\n",
      "{'epoch': 1, 'batch': 143, 'loss': 6.607378005981445}\n",
      "{'epoch': 1, 'batch': 144, 'loss': 6.4457573890686035}\n",
      "{'epoch': 1, 'batch': 145, 'loss': 6.429457664489746}\n",
      "{'epoch': 1, 'batch': 146, 'loss': 6.503732204437256}\n",
      "{'epoch': 1, 'batch': 147, 'loss': 6.471327304840088}\n",
      "{'epoch': 1, 'batch': 148, 'loss': 6.540647506713867}\n",
      "{'epoch': 1, 'batch': 149, 'loss': 6.4666666984558105}\n",
      "{'epoch': 1, 'batch': 150, 'loss': 6.499885559082031}\n",
      "{'epoch': 1, 'batch': 151, 'loss': 6.490879535675049}\n",
      "{'epoch': 1, 'batch': 152, 'loss': 6.619122505187988}\n",
      "{'epoch': 1, 'batch': 153, 'loss': 6.48985481262207}\n",
      "{'epoch': 1, 'batch': 154, 'loss': 6.749723434448242}\n",
      "{'epoch': 1, 'batch': 155, 'loss': 6.709551811218262}\n",
      "{'epoch': 1, 'batch': 156, 'loss': 6.5534162521362305}\n",
      "{'epoch': 1, 'batch': 157, 'loss': 6.490172863006592}\n",
      "{'epoch': 1, 'batch': 158, 'loss': 6.423765659332275}\n",
      "{'epoch': 1, 'batch': 159, 'loss': 6.560837745666504}\n",
      "{'epoch': 1, 'batch': 160, 'loss': 6.490839958190918}\n",
      "{'epoch': 1, 'batch': 161, 'loss': 6.588210582733154}\n",
      "{'epoch': 1, 'batch': 162, 'loss': 6.531106472015381}\n",
      "{'epoch': 1, 'batch': 163, 'loss': 6.5039286613464355}\n",
      "{'epoch': 1, 'batch': 164, 'loss': 6.576426982879639}\n",
      "{'epoch': 1, 'batch': 165, 'loss': 6.585186004638672}\n",
      "{'epoch': 1, 'batch': 166, 'loss': 6.4322991371154785}\n",
      "{'epoch': 1, 'batch': 167, 'loss': 6.519615650177002}\n",
      "{'epoch': 1, 'batch': 168, 'loss': 6.5667724609375}\n",
      "{'epoch': 1, 'batch': 169, 'loss': 6.481019020080566}\n",
      "{'epoch': 1, 'batch': 170, 'loss': 6.505322456359863}\n",
      "{'epoch': 1, 'batch': 171, 'loss': 6.483522415161133}\n",
      "{'epoch': 1, 'batch': 172, 'loss': 6.311418533325195}\n",
      "{'epoch': 1, 'batch': 173, 'loss': 6.508247375488281}\n",
      "{'epoch': 1, 'batch': 174, 'loss': 6.644639492034912}\n",
      "{'epoch': 1, 'batch': 175, 'loss': 6.4571452140808105}\n",
      "{'epoch': 1, 'batch': 176, 'loss': 6.549072265625}\n",
      "{'epoch': 1, 'batch': 177, 'loss': 6.443881988525391}\n",
      "{'epoch': 1, 'batch': 178, 'loss': 6.504714488983154}\n",
      "{'epoch': 1, 'batch': 179, 'loss': 6.5898518562316895}\n",
      "{'epoch': 1, 'batch': 180, 'loss': 6.549013614654541}\n",
      "{'epoch': 1, 'batch': 181, 'loss': 6.543004035949707}\n",
      "{'epoch': 1, 'batch': 182, 'loss': 6.3711628913879395}\n",
      "{'epoch': 1, 'batch': 183, 'loss': 6.515485763549805}\n",
      "{'epoch': 1, 'batch': 184, 'loss': 6.478979110717773}\n",
      "{'epoch': 1, 'batch': 185, 'loss': 6.546850204467773}\n",
      "{'epoch': 1, 'batch': 186, 'loss': 6.413453578948975}\n",
      "{'epoch': 1, 'batch': 187, 'loss': 6.336337089538574}\n",
      "{'epoch': 1, 'batch': 188, 'loss': 6.52394962310791}\n",
      "{'epoch': 1, 'batch': 189, 'loss': 6.547508239746094}\n",
      "{'epoch': 1, 'batch': 190, 'loss': 6.504822731018066}\n",
      "{'epoch': 1, 'batch': 191, 'loss': 6.4560627937316895}\n",
      "{'epoch': 1, 'batch': 192, 'loss': 6.4825897216796875}\n",
      "{'epoch': 1, 'batch': 193, 'loss': 6.507147312164307}\n",
      "{'epoch': 1, 'batch': 194, 'loss': 6.4870171546936035}\n",
      "{'epoch': 1, 'batch': 195, 'loss': 6.354304790496826}\n",
      "{'epoch': 1, 'batch': 196, 'loss': 6.579531669616699}\n",
      "{'epoch': 1, 'batch': 197, 'loss': 6.627634525299072}\n",
      "{'epoch': 1, 'batch': 198, 'loss': 6.543808937072754}\n",
      "{'epoch': 1, 'batch': 199, 'loss': 6.412245750427246}\n",
      "{'epoch': 1, 'batch': 200, 'loss': 6.526214599609375}\n",
      "{'epoch': 1, 'batch': 201, 'loss': 6.454569339752197}\n",
      "{'epoch': 1, 'batch': 202, 'loss': 6.514481067657471}\n",
      "{'epoch': 1, 'batch': 203, 'loss': 6.458920955657959}\n",
      "{'epoch': 1, 'batch': 204, 'loss': 6.447183609008789}\n",
      "{'epoch': 1, 'batch': 205, 'loss': 6.467724800109863}\n",
      "{'epoch': 1, 'batch': 206, 'loss': 6.449093818664551}\n",
      "{'epoch': 1, 'batch': 207, 'loss': 6.364165782928467}\n",
      "{'epoch': 1, 'batch': 208, 'loss': 6.5227885246276855}\n",
      "{'epoch': 1, 'batch': 209, 'loss': 6.468235969543457}\n",
      "{'epoch': 1, 'batch': 210, 'loss': 6.418219566345215}\n",
      "{'epoch': 1, 'batch': 211, 'loss': 6.551634788513184}\n",
      "{'epoch': 1, 'batch': 212, 'loss': 6.426957607269287}\n",
      "{'epoch': 1, 'batch': 213, 'loss': 6.45437479019165}\n",
      "{'epoch': 1, 'batch': 214, 'loss': 6.531899452209473}\n",
      "{'epoch': 1, 'batch': 215, 'loss': 6.549103260040283}\n",
      "{'epoch': 1, 'batch': 216, 'loss': 6.455516338348389}\n",
      "{'epoch': 1, 'batch': 217, 'loss': 6.468156337738037}\n",
      "{'epoch': 1, 'batch': 218, 'loss': 6.498485088348389}\n",
      "{'epoch': 1, 'batch': 219, 'loss': 6.434431552886963}\n",
      "{'epoch': 1, 'batch': 220, 'loss': 6.518749237060547}\n",
      "{'epoch': 1, 'batch': 221, 'loss': 6.415708541870117}\n",
      "{'epoch': 1, 'batch': 222, 'loss': 6.498818874359131}\n",
      "{'epoch': 1, 'batch': 223, 'loss': 6.4113450050354}\n",
      "{'epoch': 1, 'batch': 224, 'loss': 6.336691856384277}\n",
      "{'epoch': 1, 'batch': 225, 'loss': 6.487966537475586}\n",
      "{'epoch': 1, 'batch': 226, 'loss': 6.475249767303467}\n",
      "{'epoch': 1, 'batch': 227, 'loss': 6.399718761444092}\n",
      "{'epoch': 1, 'batch': 228, 'loss': 6.500823497772217}\n",
      "{'epoch': 1, 'batch': 229, 'loss': 6.354619026184082}\n",
      "{'epoch': 1, 'batch': 230, 'loss': 6.415348529815674}\n",
      "{'epoch': 1, 'batch': 231, 'loss': 6.489288330078125}\n",
      "{'epoch': 1, 'batch': 232, 'loss': 6.398436069488525}\n",
      "{'epoch': 1, 'batch': 233, 'loss': 6.434324741363525}\n",
      "{'epoch': 1, 'batch': 234, 'loss': 6.358614921569824}\n",
      "{'epoch': 1, 'batch': 235, 'loss': 6.483370780944824}\n",
      "{'epoch': 1, 'batch': 236, 'loss': 6.39421272277832}\n",
      "{'epoch': 1, 'batch': 237, 'loss': 6.513388633728027}\n",
      "{'epoch': 1, 'batch': 238, 'loss': 6.530927658081055}\n",
      "{'epoch': 1, 'batch': 239, 'loss': 6.470713138580322}\n",
      "{'epoch': 1, 'batch': 240, 'loss': 6.361957550048828}\n",
      "{'epoch': 1, 'batch': 241, 'loss': 6.327182292938232}\n",
      "{'epoch': 1, 'batch': 242, 'loss': 6.352547645568848}\n",
      "{'epoch': 1, 'batch': 243, 'loss': 6.525513648986816}\n",
      "{'epoch': 1, 'batch': 244, 'loss': 6.430840969085693}\n",
      "{'epoch': 1, 'batch': 245, 'loss': 6.574489593505859}\n",
      "{'epoch': 1, 'batch': 246, 'loss': 6.497761249542236}\n",
      "{'epoch': 1, 'batch': 247, 'loss': 6.309610366821289}\n",
      "{'epoch': 1, 'batch': 248, 'loss': 6.487525463104248}\n",
      "{'epoch': 1, 'batch': 249, 'loss': 6.429642677307129}\n",
      "{'epoch': 1, 'batch': 250, 'loss': 6.440704345703125}\n",
      "{'epoch': 1, 'batch': 251, 'loss': 6.545331954956055}\n",
      "{'epoch': 1, 'batch': 252, 'loss': 6.3807597160339355}\n",
      "{'epoch': 1, 'batch': 253, 'loss': 6.394275188446045}\n",
      "{'epoch': 1, 'batch': 254, 'loss': 6.432527542114258}\n",
      "{'epoch': 1, 'batch': 255, 'loss': 6.4051618576049805}\n",
      "{'epoch': 1, 'batch': 256, 'loss': 6.339787006378174}\n",
      "{'epoch': 1, 'batch': 257, 'loss': 6.366583347320557}\n",
      "{'epoch': 1, 'batch': 258, 'loss': 6.357071876525879}\n",
      "{'epoch': 1, 'batch': 259, 'loss': 6.401928901672363}\n",
      "{'epoch': 1, 'batch': 260, 'loss': 6.460890293121338}\n",
      "{'epoch': 1, 'batch': 261, 'loss': 6.478753089904785}\n",
      "{'epoch': 1, 'batch': 262, 'loss': 6.3871378898620605}\n",
      "{'epoch': 1, 'batch': 263, 'loss': 6.518849849700928}\n",
      "{'epoch': 1, 'batch': 264, 'loss': 6.412600517272949}\n",
      "{'epoch': 1, 'batch': 265, 'loss': 6.283487319946289}\n",
      "{'epoch': 1, 'batch': 266, 'loss': 6.439513206481934}\n",
      "{'epoch': 1, 'batch': 267, 'loss': 6.5732831954956055}\n",
      "{'epoch': 1, 'batch': 268, 'loss': 6.371601581573486}\n",
      "{'epoch': 1, 'batch': 269, 'loss': 6.414524078369141}\n",
      "{'epoch': 1, 'batch': 270, 'loss': 6.350910663604736}\n",
      "{'epoch': 1, 'batch': 271, 'loss': 6.315881729125977}\n",
      "{'epoch': 1, 'batch': 272, 'loss': 6.419314384460449}\n",
      "{'epoch': 1, 'batch': 273, 'loss': 6.3776044845581055}\n",
      "{'epoch': 1, 'batch': 274, 'loss': 6.381932735443115}\n",
      "{'epoch': 1, 'batch': 275, 'loss': 6.436201095581055}\n",
      "{'epoch': 1, 'batch': 276, 'loss': 6.415503978729248}\n",
      "{'epoch': 1, 'batch': 277, 'loss': 6.469358921051025}\n",
      "{'epoch': 1, 'batch': 278, 'loss': 6.29692268371582}\n",
      "{'epoch': 1, 'batch': 279, 'loss': 6.426701545715332}\n",
      "{'epoch': 1, 'batch': 280, 'loss': 6.369579315185547}\n",
      "{'epoch': 1, 'batch': 281, 'loss': 6.412024021148682}\n",
      "{'epoch': 1, 'batch': 282, 'loss': 6.408201694488525}\n",
      "{'epoch': 1, 'batch': 283, 'loss': 6.3238325119018555}\n",
      "{'epoch': 1, 'batch': 284, 'loss': 6.322344779968262}\n",
      "{'epoch': 1, 'batch': 285, 'loss': 6.43575382232666}\n",
      "{'epoch': 1, 'batch': 286, 'loss': 6.284555912017822}\n",
      "{'epoch': 1, 'batch': 287, 'loss': 6.331378936767578}\n",
      "{'epoch': 1, 'batch': 288, 'loss': 6.548885345458984}\n",
      "{'epoch': 1, 'batch': 289, 'loss': 6.45375919342041}\n",
      "{'epoch': 1, 'batch': 290, 'loss': 6.354630947113037}\n",
      "{'epoch': 1, 'batch': 291, 'loss': 6.304804801940918}\n",
      "{'epoch': 1, 'batch': 292, 'loss': 6.414194583892822}\n",
      "{'epoch': 1, 'batch': 293, 'loss': 6.362060070037842}\n",
      "{'epoch': 1, 'batch': 294, 'loss': 6.47053861618042}\n",
      "{'epoch': 1, 'batch': 295, 'loss': 6.459571838378906}\n",
      "{'epoch': 1, 'batch': 296, 'loss': 6.3786139488220215}\n",
      "{'epoch': 1, 'batch': 297, 'loss': 6.38261079788208}\n",
      "{'epoch': 1, 'batch': 298, 'loss': 6.3169097900390625}\n",
      "{'epoch': 1, 'batch': 299, 'loss': 6.440787315368652}\n",
      "{'epoch': 1, 'batch': 300, 'loss': 6.342230796813965}\n",
      "{'epoch': 1, 'batch': 301, 'loss': 6.472720146179199}\n",
      "{'epoch': 1, 'batch': 302, 'loss': 6.384048938751221}\n",
      "{'epoch': 1, 'batch': 303, 'loss': 6.275476455688477}\n",
      "{'epoch': 2, 'batch': 0, 'loss': 6.268514156341553}\n",
      "{'epoch': 2, 'batch': 1, 'loss': 6.366724014282227}\n",
      "{'epoch': 2, 'batch': 2, 'loss': 6.341120719909668}\n",
      "{'epoch': 2, 'batch': 3, 'loss': 6.346158027648926}\n",
      "{'epoch': 2, 'batch': 4, 'loss': 6.321251392364502}\n",
      "{'epoch': 2, 'batch': 5, 'loss': 6.456161022186279}\n",
      "{'epoch': 2, 'batch': 6, 'loss': 6.2540669441223145}\n",
      "{'epoch': 2, 'batch': 7, 'loss': 6.407474517822266}\n",
      "{'epoch': 2, 'batch': 8, 'loss': 6.325032711029053}\n",
      "{'epoch': 2, 'batch': 9, 'loss': 6.282691955566406}\n",
      "{'epoch': 2, 'batch': 10, 'loss': 6.422132968902588}\n",
      "{'epoch': 2, 'batch': 11, 'loss': 6.412936210632324}\n",
      "{'epoch': 2, 'batch': 12, 'loss': 6.500637054443359}\n",
      "{'epoch': 2, 'batch': 13, 'loss': 6.414802074432373}\n",
      "{'epoch': 2, 'batch': 14, 'loss': 6.531753063201904}\n",
      "{'epoch': 2, 'batch': 15, 'loss': 6.300574779510498}\n",
      "{'epoch': 2, 'batch': 16, 'loss': 6.3558759689331055}\n"
     ]
    }
   ],
   "source": [
    "dataset = RNN_Dataset_multiple_sources(TRAIN_TOKEN_LEN, \"mar_2023_lowercase_reviews_small_vocab.pt\", \"lowercase_garden_small_tok.pkl\", \"lowercase_music_small_tok.pkl\")\n",
    "input_size = dataset.uniq_words # Should be size of vocab?\n",
    "hidden_size = 256\n",
    "n_layers = 3\n",
    "num_epochs = 3\n",
    "\n",
    "cells_category_model = GRU_with_cells_category(input_size, hidden_size, input_size, n_layers).to(device)\n",
    "\n",
    "file_path = f\"gru_trained_cat_cells_reviews.pt\"\n",
    "\n",
    "losses_cat_cells = train(dataset, cells_category_model, num_epochs, BATCH_SIZE, True)\n",
    "\n",
    "torch.save(cells_category_model.state_dict(), file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = RNN_Dataset_multiple_sources(TRAIN_TOKEN_LEN, \"mar_2023_lowercase_reviews_small_vocab.pt\", \"lowercase_garden_small_tok.pkl\", \"lowercase_music_small_tok.pkl\")\n",
    "input_size = dataset.uniq_words # Should be size of vocab?\n",
    "hidden_size = 256\n",
    "n_layers = 3\n",
    "num_epochs = 3\n",
    "\n",
    "cells_category_edited_model = GRU_with_cells_category_edited(input_size, hidden_size, input_size, n_layers).to(device)\n",
    "\n",
    "file_path = f\"gru_trained_cat_cells_edited_reviews.pt\"\n",
    "\n",
    "losses_cat_cells_edited = train(dataset, cells_category_edited_model, num_epochs, BATCH_SIZE, True)\n",
    "\n",
    "torch.save(cells_category_edited_model.state_dict(), file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(range(len(losses_cat)), losses_cat, label=\"original\")\n",
    "ax.plot(range(len(losses_cat_cells)), losses_cat_cells, label=\"original with cells\")\n",
    "ax.plot(range(len(losses_cat_cells_edited)), losses_cat_cells_edited, label=\"edited\")\n",
    "plt.title(\"Loss over time\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' '.join(predict_with_category(dataset, category_model, text='i am', category='english', next_words=100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' '.join(predict_with_category(dataset, cells_category_model, text='i am', category='english', next_words=100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' '.join(predict_with_category(dataset, cells_category_edited_model, text='i am', category='english', next_words=100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' '.join(predict_with_category(dataset, category_model, text='i am', category='news', next_words=100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "45e7954dfd96789d14f341f824ff86e19c0f19182e76820f76f4969609b51e25"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
